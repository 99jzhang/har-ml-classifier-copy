{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "from scipy.signal import medfilt, butter, filtfilt, find_peaks\n",
    "from scipy.stats import median_abs_deviation, entropy, kurtosis, skew\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_PATH = './data/'\n",
    "DATASET_PATH = DATA_PATH + 'uci-data/'\n",
    "MODELS_PATH = DATA_PATH + 'models/raw-models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def get_raw_data_path(type, exp_id, user_id):\n",
    "    exp = exp_id if len(exp_id) == 2 else \"0\" + exp_id\n",
    "    user = user_id if len(user_id) == 2 else \"0\" + user_id\n",
    "    return \"RawData/{}_exp{}_user{}.txt\".format(type, exp, user)\n",
    "\n",
    "def apply_med_filter(column):\n",
    "    return list( medfilt(np.array(column), kernel_size=5) )\n",
    "\n",
    "# Function to design a low-pass Butterworth filter\n",
    "def butter_lowpass(cutoff, fs, order):\n",
    "    nyq = 0.5 * fs  # Nyquist frequency\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "# Function to apply the Butterworth filter\n",
    "def apply_low_butter(data, cutoff, fs, order):\n",
    "    b, a = butter_lowpass(cutoff, fs, order)\n",
    "    y = filtfilt(b, a, np.array(data), axis=0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = set()\n",
    "def extract_features(acc_data, gyro_data, label):\n",
    "    # Get each data array\n",
    "    acc_x_data = np.array([x[0] for x in acc_data])\n",
    "    acc_y_data = np.array([x[1] for x in acc_data])\n",
    "    acc_z_data = np.array([x[2] for x in acc_data])\n",
    "\n",
    "    gyro_x_data = np.array([x[0] for x in gyro_data])\n",
    "    gyro_y_data = np.array([x[1] for x in gyro_data])\n",
    "    gyro_z_data = np.array([x[2] for x in gyro_data])\n",
    "\n",
    "    # Then apply a median filter and Butterworth filter\n",
    "    acc_x_data = apply_low_butter(apply_med_filter(acc_x_data), 20, 50, 3)\n",
    "    acc_y_data = apply_low_butter(apply_med_filter(acc_y_data), 20, 50, 3)\n",
    "    acc_z_data = apply_low_butter(apply_med_filter(acc_z_data), 20, 50, 3)\n",
    "\n",
    "    gyro_x_data = apply_low_butter(apply_med_filter(gyro_x_data), 20, 50, 3)\n",
    "    gyro_y_data = apply_low_butter(apply_med_filter(gyro_y_data), 20, 50, 3)\n",
    "    gyro_z_data = apply_low_butter(apply_med_filter(gyro_z_data), 20, 50, 3)\n",
    "\n",
    "    # Then another Butterworth filter to get body and gravity acceleration\n",
    "\n",
    "    body_acc_x_data = apply_low_butter(acc_x_data, 0.3, 50, 3)\n",
    "    body_acc_y_data = apply_low_butter(acc_y_data, 0.3, 50, 3)\n",
    "    body_acc_z_data = apply_low_butter(acc_z_data, 0.3, 50, 3)\n",
    "\n",
    "    gravity_acc_x_data = acc_x_data - body_acc_x_data \n",
    "    gravity_acc_y_data = acc_y_data - body_acc_y_data \n",
    "    gravity_acc_z_data = acc_z_data - body_acc_z_data \n",
    "\n",
    "    # Now put all this data in a dictionary for ease of use\n",
    "    data_dict = {\n",
    "        \"bodyAccX\": body_acc_x_data,\n",
    "        \"bodyAccY\": body_acc_y_data,\n",
    "        \"bodyAccZ\": body_acc_z_data,\n",
    "        \"gravityAccX\": gravity_acc_x_data,\n",
    "        \"gravityAccY\": gravity_acc_y_data,\n",
    "        \"gravityAccZ\": gravity_acc_z_data,\n",
    "        \"gyroX\": gyro_x_data,\n",
    "        \"gyroY\": gyro_y_data,\n",
    "        \"gyroZ\": gyro_z_data,\n",
    "    }\n",
    "\n",
    "    features = []\n",
    "\n",
    "    \n",
    "    # Get jerk and magnitude time series values\n",
    "    dict_keys = list(data_dict.keys())\n",
    "    for d in dict_keys:\n",
    "        jerk_feature = d[:-1] + \"Jerk\" + d[-1]\n",
    "        if \"gravityAcc\" not in d:\n",
    "            data_dict[jerk_feature] = np.array(np.diff(data_dict[d])/0.02)\n",
    "            \n",
    "\n",
    "    data_dict[\"bodyAccMag\"] = np.sqrt(body_acc_x_data**2 + body_acc_y_data**2 + body_acc_y_data**2)\n",
    "    data_dict[\"bodyAccJerkMag\"] = np.sqrt(data_dict[\"bodyAccJerkX\"]**2 + data_dict[\"bodyAccJerkY\"]**2 + data_dict[\"bodyAccJerkZ\"]**2)\n",
    "    data_dict[\"gravityAccMag\"] = np.sqrt(gravity_acc_x_data**2 + gravity_acc_y_data**2 + gravity_acc_y_data**2)\n",
    "    data_dict[\"gyroMag\"] = np.sqrt(gyro_x_data**2 + gyro_y_data**2 + gyro_y_data**2)\n",
    "    data_dict[\"gyroJerkMag\"] = np.sqrt(data_dict[\"gyroJerkX\"]**2 + data_dict[\"gyroJerkY\"]**2 + data_dict[\"gyroJerkZ\"]**2)\n",
    "\n",
    "    # Feature extraction time!\n",
    "    dict_keys = list(data_dict.keys())\n",
    "    for d in dict_keys:\n",
    "        # Mean\n",
    "        features.append(data_dict[d].mean())\n",
    "        feature_names.add(d + \"_Mean\")\n",
    "\n",
    "        # Median\n",
    "        features.append(np.median(data_dict[d]))\n",
    "        feature_names.add(d + \"_Median\")\n",
    "\n",
    "        # Min, Max\n",
    "        features.append(np.max(data_dict[d]))\n",
    "        feature_names.add(d + \"_Min\")\n",
    "        features.append(np.min(data_dict[d]))\n",
    "        feature_names.add(d + \"_Max\")\n",
    "\n",
    "        # Standard Deviation\n",
    "        features.append(np.std(data_dict[d]))\n",
    "        feature_names.add(d + \"_Std\")\n",
    "\n",
    "        # Median absolute deviation\n",
    "        features.append(median_abs_deviation(data_dict[d]))\n",
    "        feature_names.add(d + \"_Mad\")\n",
    "\n",
    "        # Range\n",
    "        features.append(np.max(data_dict[d]) - np.min(data_dict[d]))\n",
    "        feature_names.add(d + \"_Mad\")\n",
    "\n",
    "        # Interquartile range\n",
    "        lq, uq = np.percentile(data_dict[d], [75, 25])\n",
    "        features.append(uq - lq)\n",
    "        feature_names.add(d + \"_Iqr\")\n",
    "\n",
    "        # Root mean squared\n",
    "        features.append( np.sqrt(np.mean(data_dict[d]**2)) )\n",
    "        feature_names.add(d + \"_Rms\")\n",
    "\n",
    "        # Peak count\n",
    "        features.append( find_peaks(data_dict[d]) )\n",
    "        feature_names.add(d + \"_Peak_count\")\n",
    "\n",
    "        # Signal energy\n",
    "        features.append( (np.sum(data_dict[d]) ** 2) / len(data_dict[d]))\n",
    "        feature_names.add(d + \"_Energy\")\n",
    "\n",
    "        # Signal entropy\n",
    "        features.append( entropy(data_dict[d]) )\n",
    "        feature_names.add(d + \"_Entropy\")\n",
    "\n",
    "        # Skewness & Kurtosis\n",
    "        features.append( skew(data_dict[d]) )\n",
    "        feature_names.add(d + \"_Skewness\")\n",
    "        features.append( kurtosis(data_dict[d]) )\n",
    "        feature_names.add(d + \"_Kurtosis\")\n",
    "\n",
    "    # Finally calculate signal magnitude area\n",
    "    features.append( np.mean(\n",
    "        np.absolute(data_dict[\"bodyAccX\"]) +\n",
    "        np.absolute(data_dict[\"bodyAccY\"]) +\n",
    "        np.absolute(data_dict[\"bodyAccZ\"]) \n",
    "    ))\n",
    "    feature_names.add(\"bodyAcc_Sma\")\n",
    "    features.append( np.mean(\n",
    "        np.absolute(data_dict[\"gravityAccX\"]) +\n",
    "        np.absolute(data_dict[\"gravityAccY\"]) +\n",
    "        np.absolute(data_dict[\"gravityAccZ\"]) \n",
    "    ))\n",
    "    feature_names.add(\"gravityAcc_Sma\")\n",
    "    features.append( np.mean(\n",
    "        np.absolute(data_dict[\"gyroX\"]) +\n",
    "        np.absolute(data_dict[\"gyroY\"]) +\n",
    "        np.absolute(data_dict[\"gyroZ\"]) \n",
    "    ))\n",
    "    feature_names.add(\"gyro_Sma\")\n",
    "    features.append( np.mean(\n",
    "        np.absolute(data_dict[\"bodyAccJerkX\"]) +\n",
    "        np.absolute(data_dict[\"bodyAccJerkY\"]) +\n",
    "        np.absolute(data_dict[\"bodyAccJerkZ\"]) \n",
    "    ))\n",
    "    feature_names.add(\"bodyAccJerk_Sma\")\n",
    "    features.append( np.mean(\n",
    "        np.absolute(data_dict[\"gyroJerkX\"]) +\n",
    "        np.absolute(data_dict[\"gyroJerkY\"]) +\n",
    "        np.absolute(data_dict[\"gyroJerkZ\"]) \n",
    "    ))\n",
    "    feature_names.add(\"gyroJerk_Sma\")\n",
    "\n",
    "    # Finally add label\n",
    "    features.append(label)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Experiment ID: 1 User ID: 1, Activity: 5\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 7\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 4\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 8\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 5\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 11\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 6\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 10\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 4\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 9\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 6\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 12\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 1\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 1\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 1\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 1\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 3\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 2\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 3\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 2\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 3\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 1 User ID: 1, Activity: 2\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "Loading Experiment ID: 2 User ID: 1, Activity: 5\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m acc_data \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mfloat\u001b[39m(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m raw_acc_data[start \u001b[38;5;241m+\u001b[39m i: start \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m128\u001b[39m]]\n\u001b[1;32m     29\u001b[0m gyro_data \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mfloat\u001b[39m(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)]  \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m raw_acc_data[start \u001b[38;5;241m+\u001b[39m i: start \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m128\u001b[39m]]\n\u001b[0;32m---> 31\u001b[0m feature_column \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43macc_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgyro_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessed_label\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n",
      "Cell \u001b[0;32mIn[19], line 110\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(acc_data, gyro_data, label)\u001b[0m\n\u001b[1;32m    108\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend( skew(data_dict[d]) )\n\u001b[1;32m    109\u001b[0m     feature_names\u001b[38;5;241m.\u001b[39madd(d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Skewness\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 110\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend( \u001b[43mkurtosis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m )\n\u001b[1;32m    111\u001b[0m     feature_names\u001b[38;5;241m.\u001b[39madd(d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Kurtosis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Finally calculate signal magnitude area\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:522\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    520\u001b[0m     samples \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(sample\u001b[38;5;241m.\u001b[39mravel()) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples]\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 522\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m     axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(axis)\n\u001b[1;32m    524\u001b[0m     n_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:53\u001b[0m, in \u001b[0;36m_broadcast_arrays\u001b[0;34m(arrays, axis, xp)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     new_shapes \u001b[38;5;241m=\u001b[39m [new_shapes]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(arrays)\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m array, new_shape \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arrays, new_shapes)]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/numpy/lib/stride_tricks.py:413\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_broadcast_to_dispatcher, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_to\u001b[39m(array, shape, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    369\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Broadcast an array to a new shape.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m           [1, 2, 3]])\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreadonly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/numpy/lib/stride_tricks.py:341\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_broadcast_to\u001b[39m(array, shape, subok, readonly):\n\u001b[0;32m--> 341\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(shape) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m (shape,)\n\u001b[1;32m    342\u001b[0m     array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(array, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39msubok)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shape \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mshape:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/numpy/lib/function_base.py:348\u001b[0m, in \u001b[0;36miterable\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    344\u001b[0m         indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(indexer)\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m[indexer]\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterable\u001b[39m(y):\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    Check whether or not an object can be iterated over.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "raw_data_labels = open(\"labels.txt\", 'r').readlines()\n",
    "\n",
    "raw_path = None\n",
    "raw_acc_data = None\n",
    "raw_gyro_data = None\n",
    "\n",
    "complete_dataset = pd.DataFrame()\n",
    "\n",
    "\n",
    "for label in raw_data_labels:\n",
    "    processed_label = label.strip(\"\\n\").split(\" \")\n",
    "    processed_label[3] = int(processed_label[3]) - 1\n",
    "    processed_label[4] = int(processed_label[4])\n",
    "    print(\"Loading Experiment ID: {} User ID: {}, Activity: {}\".format(processed_label[0], processed_label[1], processed_label[2]))\n",
    "\n",
    "    if get_raw_data_path('acc', processed_label[0], processed_label[1]) != raw_path:\n",
    "        raw_path = get_raw_data_path('gyro', processed_label[0], processed_label[1])\n",
    "        raw_gyro_data = open(raw_path, 'r').readlines()\n",
    "        raw_path = get_raw_data_path('acc', processed_label[0], processed_label[1])\n",
    "        raw_acc_data = open(raw_path, 'r').readlines()\n",
    "\n",
    "    start = processed_label[3]\n",
    "    end = processed_label[4]\n",
    "    length = end-start\n",
    "    i = 0\n",
    "    while i + 128 < length:\n",
    "        acc_data = [[float(y) for y in x.strip(\"\\n\").split(\" \")] for x in raw_acc_data[start + i: start + i + 128]]\n",
    "        gyro_data = [[float(y) for y in x.strip(\"\\n\").split(\" \")]  for x in raw_acc_data[start + i: start + i + 128]]\n",
    "\n",
    "        feature_column = extract_features(\n",
    "            acc_data,\n",
    "            gyro_data,\n",
    "            processed_label[2]\n",
    "        )\n",
    "        i += 64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
