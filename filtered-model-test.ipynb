{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import math\n",
    "import time \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_PATH = './data/'\n",
    "DATASET_PATH = DATA_PATH + 'uci-data/'\n",
    "MODELS_PATH = DATA_PATH + 'models/filtered-models/'\n",
    "FEATURES = ['bodyAccX', 'gravityAccX', 'accY', 'gravityAccY', 'accZ', 'gravityAccZ', 'gyroX', 'gyroY', 'gyroZ', \"subject\", \"activity\"]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SAMPLE_SIZE = BATCH_SIZE * 1500\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/lt/w0169b7x5ml3psz3nly9vj3m0000gn/T/ipykernel_45211/4155984055.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  complete_set = pd.read_csv(DATA_PATH + \"self-calculated/complete-filtered.txt\", sep='\\s+', header=None)\n"
     ]
    }
   ],
   "source": [
    "complete_set = pd.read_csv(DATA_PATH + \"self-calculated/complete-filtered.txt\", sep='\\s+', header=None)\n",
    "complete_set.columns = FEATURES\n",
    "train_set, test_set = train_test_split(complete_set, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model\n",
    "device = None\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "class RawDataModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential_module = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=len(FEATURES)-1, out_channels=256, kernel_size=1),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool1d(1),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Conv1d(in_channels=256, out_channels=128, kernel_size=1),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool1d(1),\n",
    "            nn.BatchNorm1d(128),\n",
    "\n",
    "            nn.Conv1d(in_channels=128, out_channels=64, kernel_size=1),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool1d(1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(128, 12),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential_module(x)\n",
    "    \n",
    "model = RawDataModel().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    # Get batch num\n",
    "    num_batches = len(dataloader.dataset) / BATCH_SIZE\n",
    "    i = 0\n",
    "\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.unsqueeze(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        i += 1\n",
    "        if batch % 50 == 0:\n",
    "            print(f\"loss: {loss.item()}, batch: {i} out of {math.ceil(num_batches)}\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.unsqueeze(-1)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    return(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "class HAPTDataset(Dataset):\n",
    "    def __init__(self, dataset, features, label):\n",
    "        '''\n",
    "        self.data = torch.tensor(dataset[features].values, dtype=torch.float32)[:SAMPLE_SIZE]\n",
    "        self.labels = torch.tensor(dataset[label].values, dtype=torch.float32)[:SAMPLE_SIZE]\n",
    "        '''\n",
    "        max_size = len(dataset) - (len(dataset) % 32)\n",
    "        self.data = torch.tensor(dataset[features].values, dtype=torch.float32)[:max_size]\n",
    "        self.labels = torch.tensor(dataset[label].values, dtype=torch.float32)[:max_size]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "train_dataset = HAPTDataset(train_set, train_set.columns[:-1], 'activity')\n",
    "test_dataset = HAPTDataset(test_set, test_set.columns[:-1], 'activity')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.498300075531006, batch: 1 out of 17841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.12/site-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.436281681060791, batch: 51 out of 17841\n",
      "loss: 2.3011090755462646, batch: 101 out of 17841\n",
      "loss: 2.2537169456481934, batch: 151 out of 17841\n",
      "loss: 2.234772205352783, batch: 201 out of 17841\n",
      "loss: 2.1094446182250977, batch: 251 out of 17841\n",
      "loss: 2.035842180252075, batch: 301 out of 17841\n",
      "loss: 2.1640610694885254, batch: 351 out of 17841\n",
      "loss: 2.2120652198791504, batch: 401 out of 17841\n",
      "loss: 1.959302544593811, batch: 451 out of 17841\n",
      "loss: 2.167409658432007, batch: 501 out of 17841\n",
      "loss: 2.1770434379577637, batch: 551 out of 17841\n",
      "loss: 1.9949617385864258, batch: 601 out of 17841\n",
      "loss: 2.059528350830078, batch: 651 out of 17841\n",
      "loss: 1.9220120906829834, batch: 701 out of 17841\n",
      "loss: 1.9277477264404297, batch: 751 out of 17841\n",
      "loss: 2.0033063888549805, batch: 801 out of 17841\n",
      "loss: 2.1151883602142334, batch: 851 out of 17841\n",
      "loss: 2.0332794189453125, batch: 901 out of 17841\n",
      "loss: 2.0315756797790527, batch: 951 out of 17841\n",
      "loss: 1.946389079093933, batch: 1001 out of 17841\n",
      "loss: 1.8945059776306152, batch: 1051 out of 17841\n",
      "loss: 1.907512903213501, batch: 1101 out of 17841\n",
      "loss: 2.0115127563476562, batch: 1151 out of 17841\n",
      "loss: 2.0508925914764404, batch: 1201 out of 17841\n",
      "loss: 2.0461766719818115, batch: 1251 out of 17841\n",
      "loss: 1.9406245946884155, batch: 1301 out of 17841\n",
      "loss: 1.9589407444000244, batch: 1351 out of 17841\n",
      "loss: 2.137535572052002, batch: 1401 out of 17841\n",
      "loss: 1.9522379636764526, batch: 1451 out of 17841\n",
      "loss: 1.9861429929733276, batch: 1501 out of 17841\n",
      "loss: 1.9310197830200195, batch: 1551 out of 17841\n",
      "loss: 1.9674618244171143, batch: 1601 out of 17841\n",
      "loss: 2.025249481201172, batch: 1651 out of 17841\n",
      "loss: 2.063872814178467, batch: 1701 out of 17841\n",
      "loss: 1.7647860050201416, batch: 1751 out of 17841\n",
      "loss: 1.9138824939727783, batch: 1801 out of 17841\n",
      "loss: 1.8914902210235596, batch: 1851 out of 17841\n",
      "loss: 1.845807671546936, batch: 1901 out of 17841\n",
      "loss: 2.036045789718628, batch: 1951 out of 17841\n",
      "loss: 1.838679552078247, batch: 2001 out of 17841\n",
      "loss: 1.9257246255874634, batch: 2051 out of 17841\n",
      "loss: 1.9665559530258179, batch: 2101 out of 17841\n",
      "loss: 2.0935845375061035, batch: 2151 out of 17841\n",
      "loss: 1.8239542245864868, batch: 2201 out of 17841\n",
      "loss: 1.9347710609436035, batch: 2251 out of 17841\n",
      "loss: 2.0768332481384277, batch: 2301 out of 17841\n",
      "loss: 2.010181188583374, batch: 2351 out of 17841\n",
      "loss: 1.8343443870544434, batch: 2401 out of 17841\n",
      "loss: 1.9917457103729248, batch: 2451 out of 17841\n",
      "loss: 1.976784348487854, batch: 2501 out of 17841\n",
      "loss: 1.8038923740386963, batch: 2551 out of 17841\n",
      "loss: 1.907294511795044, batch: 2601 out of 17841\n",
      "loss: 2.003589630126953, batch: 2651 out of 17841\n",
      "loss: 1.9209330081939697, batch: 2701 out of 17841\n",
      "loss: 1.8653502464294434, batch: 2751 out of 17841\n",
      "loss: 1.7879451513290405, batch: 2801 out of 17841\n",
      "loss: 1.9247339963912964, batch: 2851 out of 17841\n",
      "loss: 1.8598687648773193, batch: 2901 out of 17841\n",
      "loss: 1.9451892375946045, batch: 2951 out of 17841\n",
      "loss: 1.9710322618484497, batch: 3001 out of 17841\n",
      "loss: 1.8734822273254395, batch: 3051 out of 17841\n",
      "loss: 1.970574140548706, batch: 3101 out of 17841\n",
      "loss: 2.016408681869507, batch: 3151 out of 17841\n",
      "loss: 1.8961901664733887, batch: 3201 out of 17841\n",
      "loss: 1.9137589931488037, batch: 3251 out of 17841\n",
      "loss: 1.7026530504226685, batch: 3301 out of 17841\n",
      "loss: 1.7017521858215332, batch: 3351 out of 17841\n",
      "loss: 1.9533565044403076, batch: 3401 out of 17841\n",
      "loss: 2.0523064136505127, batch: 3451 out of 17841\n",
      "loss: 1.9278684854507446, batch: 3501 out of 17841\n",
      "loss: 1.827331304550171, batch: 3551 out of 17841\n",
      "loss: 1.8644819259643555, batch: 3601 out of 17841\n",
      "loss: 1.8991518020629883, batch: 3651 out of 17841\n",
      "loss: 1.7782764434814453, batch: 3701 out of 17841\n",
      "loss: 1.832611322402954, batch: 3751 out of 17841\n",
      "loss: 1.8027722835540771, batch: 3801 out of 17841\n",
      "loss: 2.080951452255249, batch: 3851 out of 17841\n",
      "loss: 1.8998911380767822, batch: 3901 out of 17841\n",
      "loss: 1.8360240459442139, batch: 3951 out of 17841\n",
      "loss: 1.820712685585022, batch: 4001 out of 17841\n",
      "loss: 2.013339042663574, batch: 4051 out of 17841\n",
      "loss: 1.8725495338439941, batch: 4101 out of 17841\n",
      "loss: 1.7984216213226318, batch: 4151 out of 17841\n",
      "loss: 1.8197038173675537, batch: 4201 out of 17841\n",
      "loss: 1.8075661659240723, batch: 4251 out of 17841\n",
      "loss: 1.9638714790344238, batch: 4301 out of 17841\n",
      "loss: 1.917412281036377, batch: 4351 out of 17841\n",
      "loss: 1.8998055458068848, batch: 4401 out of 17841\n",
      "loss: 2.1122677326202393, batch: 4451 out of 17841\n",
      "loss: 1.8745920658111572, batch: 4501 out of 17841\n",
      "loss: 1.9531121253967285, batch: 4551 out of 17841\n",
      "loss: 1.8249242305755615, batch: 4601 out of 17841\n",
      "loss: 1.738938570022583, batch: 4651 out of 17841\n",
      "loss: 2.0453855991363525, batch: 4701 out of 17841\n",
      "loss: 1.954376220703125, batch: 4751 out of 17841\n",
      "loss: 1.968782901763916, batch: 4801 out of 17841\n",
      "loss: 1.8493320941925049, batch: 4851 out of 17841\n",
      "loss: 1.9053387641906738, batch: 4901 out of 17841\n",
      "loss: 1.9513801336288452, batch: 4951 out of 17841\n",
      "loss: 1.9670391082763672, batch: 5001 out of 17841\n",
      "loss: 1.8457002639770508, batch: 5051 out of 17841\n",
      "loss: 1.7828664779663086, batch: 5101 out of 17841\n",
      "loss: 1.9418896436691284, batch: 5151 out of 17841\n",
      "loss: 1.9670507907867432, batch: 5201 out of 17841\n",
      "loss: 1.8420591354370117, batch: 5251 out of 17841\n",
      "loss: 1.7765883207321167, batch: 5301 out of 17841\n",
      "loss: 1.8094539642333984, batch: 5351 out of 17841\n",
      "loss: 1.9833343029022217, batch: 5401 out of 17841\n",
      "loss: 1.771176815032959, batch: 5451 out of 17841\n",
      "loss: 1.7275604009628296, batch: 5501 out of 17841\n",
      "loss: 1.7846065759658813, batch: 5551 out of 17841\n",
      "loss: 1.9606133699417114, batch: 5601 out of 17841\n",
      "loss: 2.0659537315368652, batch: 5651 out of 17841\n",
      "loss: 1.8753160238265991, batch: 5701 out of 17841\n",
      "loss: 1.882946491241455, batch: 5751 out of 17841\n",
      "loss: 1.8357913494110107, batch: 5801 out of 17841\n",
      "loss: 1.854966402053833, batch: 5851 out of 17841\n",
      "loss: 2.1393961906433105, batch: 5901 out of 17841\n",
      "loss: 2.0352697372436523, batch: 5951 out of 17841\n",
      "loss: 1.9507207870483398, batch: 6001 out of 17841\n",
      "loss: 1.9168598651885986, batch: 6051 out of 17841\n",
      "loss: 1.766343593597412, batch: 6101 out of 17841\n",
      "loss: 1.860048770904541, batch: 6151 out of 17841\n",
      "loss: 1.889369249343872, batch: 6201 out of 17841\n",
      "loss: 1.8923561573028564, batch: 6251 out of 17841\n",
      "loss: 1.9037736654281616, batch: 6301 out of 17841\n",
      "loss: 1.7733922004699707, batch: 6351 out of 17841\n",
      "loss: 1.867945909500122, batch: 6401 out of 17841\n",
      "loss: 1.909977674484253, batch: 6451 out of 17841\n",
      "loss: 1.7960376739501953, batch: 6501 out of 17841\n",
      "loss: 1.8920166492462158, batch: 6551 out of 17841\n",
      "loss: 1.9532108306884766, batch: 6601 out of 17841\n",
      "loss: 2.012460231781006, batch: 6651 out of 17841\n",
      "loss: 1.8516690731048584, batch: 6701 out of 17841\n",
      "loss: 1.7243441343307495, batch: 6751 out of 17841\n",
      "loss: 1.9539906978607178, batch: 6801 out of 17841\n",
      "loss: 1.84041428565979, batch: 6851 out of 17841\n",
      "loss: 1.9970006942749023, batch: 6901 out of 17841\n",
      "loss: 1.8512208461761475, batch: 6951 out of 17841\n",
      "loss: 1.884185791015625, batch: 7001 out of 17841\n",
      "loss: 1.808005690574646, batch: 7051 out of 17841\n",
      "loss: 1.857211947441101, batch: 7101 out of 17841\n",
      "loss: 1.9495868682861328, batch: 7151 out of 17841\n",
      "loss: 1.9886252880096436, batch: 7201 out of 17841\n",
      "loss: 1.7753536701202393, batch: 7251 out of 17841\n",
      "loss: 1.9480829238891602, batch: 7301 out of 17841\n",
      "loss: 1.9448926448822021, batch: 7351 out of 17841\n",
      "loss: 1.8200205564498901, batch: 7401 out of 17841\n",
      "loss: 1.967240810394287, batch: 7451 out of 17841\n",
      "loss: 1.945930004119873, batch: 7501 out of 17841\n",
      "loss: 1.875271201133728, batch: 7551 out of 17841\n",
      "loss: 1.9516788721084595, batch: 7601 out of 17841\n",
      "loss: 1.8615188598632812, batch: 7651 out of 17841\n",
      "loss: 1.8643667697906494, batch: 7701 out of 17841\n",
      "loss: 1.9724466800689697, batch: 7751 out of 17841\n",
      "loss: 2.0014498233795166, batch: 7801 out of 17841\n",
      "loss: 1.8122177124023438, batch: 7851 out of 17841\n",
      "loss: 1.8037543296813965, batch: 7901 out of 17841\n",
      "loss: 1.6122043132781982, batch: 7951 out of 17841\n",
      "loss: 1.9249532222747803, batch: 8001 out of 17841\n",
      "loss: 1.7737714052200317, batch: 8051 out of 17841\n",
      "loss: 1.8700060844421387, batch: 8101 out of 17841\n",
      "loss: 1.8697373867034912, batch: 8151 out of 17841\n",
      "loss: 1.7609736919403076, batch: 8201 out of 17841\n",
      "loss: 2.003904342651367, batch: 8251 out of 17841\n",
      "loss: 1.869559645652771, batch: 8301 out of 17841\n",
      "loss: 1.9294414520263672, batch: 8351 out of 17841\n",
      "loss: 1.9662727117538452, batch: 8401 out of 17841\n",
      "loss: 1.8584243059158325, batch: 8451 out of 17841\n",
      "loss: 1.9924365282058716, batch: 8501 out of 17841\n",
      "loss: 1.843794584274292, batch: 8551 out of 17841\n",
      "loss: 1.9097137451171875, batch: 8601 out of 17841\n",
      "loss: 1.9335277080535889, batch: 8651 out of 17841\n",
      "loss: 1.7529540061950684, batch: 8701 out of 17841\n",
      "loss: 1.689626693725586, batch: 8751 out of 17841\n",
      "loss: 1.8320481777191162, batch: 8801 out of 17841\n",
      "loss: 1.9415782690048218, batch: 8851 out of 17841\n",
      "loss: 1.8827842473983765, batch: 8901 out of 17841\n",
      "loss: 1.893636703491211, batch: 8951 out of 17841\n",
      "loss: 1.9852781295776367, batch: 9001 out of 17841\n",
      "loss: 1.7317852973937988, batch: 9051 out of 17841\n",
      "loss: 1.7399660348892212, batch: 9101 out of 17841\n",
      "loss: 1.7878737449645996, batch: 9151 out of 17841\n",
      "loss: 1.9055767059326172, batch: 9201 out of 17841\n",
      "loss: 1.8361198902130127, batch: 9251 out of 17841\n",
      "loss: 1.888261318206787, batch: 9301 out of 17841\n",
      "loss: 1.801253080368042, batch: 9351 out of 17841\n",
      "loss: 1.906520128250122, batch: 9401 out of 17841\n",
      "loss: 1.9721386432647705, batch: 9451 out of 17841\n",
      "loss: 1.8379967212677002, batch: 9501 out of 17841\n",
      "loss: 1.9719929695129395, batch: 9551 out of 17841\n",
      "loss: 1.783743977546692, batch: 9601 out of 17841\n",
      "loss: 1.8356149196624756, batch: 9651 out of 17841\n",
      "loss: 1.978083610534668, batch: 9701 out of 17841\n",
      "loss: 1.8587298393249512, batch: 9751 out of 17841\n",
      "loss: 1.9317030906677246, batch: 9801 out of 17841\n",
      "loss: 1.8634467124938965, batch: 9851 out of 17841\n",
      "loss: 1.7303237915039062, batch: 9901 out of 17841\n",
      "loss: 1.9422016143798828, batch: 9951 out of 17841\n",
      "loss: 1.8903776407241821, batch: 10001 out of 17841\n",
      "loss: 1.8976659774780273, batch: 10051 out of 17841\n",
      "loss: 1.8312993049621582, batch: 10101 out of 17841\n",
      "loss: 1.8133578300476074, batch: 10151 out of 17841\n",
      "loss: 2.030609607696533, batch: 10201 out of 17841\n",
      "loss: 1.947188377380371, batch: 10251 out of 17841\n",
      "loss: 1.991584300994873, batch: 10301 out of 17841\n",
      "loss: 1.9322930574417114, batch: 10351 out of 17841\n",
      "loss: 1.8501662015914917, batch: 10401 out of 17841\n",
      "loss: 1.8669688701629639, batch: 10451 out of 17841\n",
      "loss: 1.886979579925537, batch: 10501 out of 17841\n",
      "loss: 1.936866044998169, batch: 10551 out of 17841\n",
      "loss: 1.7982444763183594, batch: 10601 out of 17841\n",
      "loss: 1.8792661428451538, batch: 10651 out of 17841\n",
      "loss: 1.8294860124588013, batch: 10701 out of 17841\n",
      "loss: 1.7125577926635742, batch: 10751 out of 17841\n",
      "loss: 1.8330351114273071, batch: 10801 out of 17841\n",
      "loss: 1.864209771156311, batch: 10851 out of 17841\n",
      "loss: 1.8001770973205566, batch: 10901 out of 17841\n",
      "loss: 1.8112573623657227, batch: 10951 out of 17841\n",
      "loss: 1.8498953580856323, batch: 11001 out of 17841\n",
      "loss: 1.8008536100387573, batch: 11051 out of 17841\n",
      "loss: 1.7424468994140625, batch: 11101 out of 17841\n",
      "loss: 2.037067413330078, batch: 11151 out of 17841\n",
      "loss: 1.9006456136703491, batch: 11201 out of 17841\n",
      "loss: 1.9265542030334473, batch: 11251 out of 17841\n",
      "loss: 1.9561638832092285, batch: 11301 out of 17841\n",
      "loss: 1.958095908164978, batch: 11351 out of 17841\n",
      "loss: 1.8086624145507812, batch: 11401 out of 17841\n",
      "loss: 1.8986146450042725, batch: 11451 out of 17841\n",
      "loss: 1.9267024993896484, batch: 11501 out of 17841\n",
      "loss: 1.8663756847381592, batch: 11551 out of 17841\n",
      "loss: 1.910994052886963, batch: 11601 out of 17841\n",
      "loss: 1.7785913944244385, batch: 11651 out of 17841\n",
      "loss: 1.9453543424606323, batch: 11701 out of 17841\n",
      "loss: 1.891671895980835, batch: 11751 out of 17841\n",
      "loss: 1.9646666049957275, batch: 11801 out of 17841\n",
      "loss: 1.7240862846374512, batch: 11851 out of 17841\n",
      "loss: 1.8294932842254639, batch: 11901 out of 17841\n",
      "loss: 1.990007758140564, batch: 11951 out of 17841\n",
      "loss: 1.875009298324585, batch: 12001 out of 17841\n",
      "loss: 1.835165023803711, batch: 12051 out of 17841\n",
      "loss: 1.885015606880188, batch: 12101 out of 17841\n",
      "loss: 1.8778568506240845, batch: 12151 out of 17841\n",
      "loss: 1.9341833591461182, batch: 12201 out of 17841\n",
      "loss: 1.9072201251983643, batch: 12251 out of 17841\n",
      "loss: 1.9170278310775757, batch: 12301 out of 17841\n",
      "loss: 1.7338111400604248, batch: 12351 out of 17841\n",
      "loss: 1.9213789701461792, batch: 12401 out of 17841\n",
      "loss: 1.7843906879425049, batch: 12451 out of 17841\n",
      "loss: 1.907831072807312, batch: 12501 out of 17841\n",
      "loss: 1.8808993101119995, batch: 12551 out of 17841\n",
      "loss: 1.7639251947402954, batch: 12601 out of 17841\n",
      "loss: 1.8100953102111816, batch: 12651 out of 17841\n",
      "loss: 1.8742910623550415, batch: 12701 out of 17841\n",
      "loss: 1.8589155673980713, batch: 12751 out of 17841\n",
      "loss: 1.9505119323730469, batch: 12801 out of 17841\n",
      "loss: 1.8916192054748535, batch: 12851 out of 17841\n",
      "loss: 1.8761128187179565, batch: 12901 out of 17841\n",
      "loss: 1.7975959777832031, batch: 12951 out of 17841\n",
      "loss: 1.8571425676345825, batch: 13001 out of 17841\n",
      "loss: 1.9095680713653564, batch: 13051 out of 17841\n",
      "loss: 1.925184726715088, batch: 13101 out of 17841\n",
      "loss: 1.920273780822754, batch: 13151 out of 17841\n",
      "loss: 1.9263877868652344, batch: 13201 out of 17841\n",
      "loss: 1.9257713556289673, batch: 13251 out of 17841\n",
      "loss: 1.7869046926498413, batch: 13301 out of 17841\n",
      "loss: 1.8961236476898193, batch: 13351 out of 17841\n",
      "loss: 1.8327155113220215, batch: 13401 out of 17841\n",
      "loss: 2.0478076934814453, batch: 13451 out of 17841\n",
      "loss: 1.7438141107559204, batch: 13501 out of 17841\n",
      "loss: 1.7866955995559692, batch: 13551 out of 17841\n",
      "loss: 1.8970094919204712, batch: 13601 out of 17841\n",
      "loss: 1.8060702085494995, batch: 13651 out of 17841\n",
      "loss: 1.760211706161499, batch: 13701 out of 17841\n",
      "loss: 1.8838014602661133, batch: 13751 out of 17841\n",
      "loss: 1.908415675163269, batch: 13801 out of 17841\n",
      "loss: 1.7525358200073242, batch: 13851 out of 17841\n",
      "loss: 1.8403682708740234, batch: 13901 out of 17841\n",
      "loss: 1.8790626525878906, batch: 13951 out of 17841\n",
      "loss: 1.9184319972991943, batch: 14001 out of 17841\n",
      "loss: 1.904968500137329, batch: 14051 out of 17841\n",
      "loss: 1.7801704406738281, batch: 14101 out of 17841\n",
      "loss: 1.9048926830291748, batch: 14151 out of 17841\n",
      "loss: 1.784304141998291, batch: 14201 out of 17841\n",
      "loss: 1.8760676383972168, batch: 14251 out of 17841\n",
      "loss: 1.909630537033081, batch: 14301 out of 17841\n",
      "loss: 1.7933335304260254, batch: 14351 out of 17841\n",
      "loss: 1.7834901809692383, batch: 14401 out of 17841\n",
      "loss: 1.9503453969955444, batch: 14451 out of 17841\n",
      "loss: 1.7471373081207275, batch: 14501 out of 17841\n",
      "loss: 1.7245726585388184, batch: 14551 out of 17841\n",
      "loss: 1.9263091087341309, batch: 14601 out of 17841\n",
      "loss: 1.9201796054840088, batch: 14651 out of 17841\n",
      "loss: 1.8275716304779053, batch: 14701 out of 17841\n",
      "loss: 1.860684871673584, batch: 14751 out of 17841\n",
      "loss: 1.8922042846679688, batch: 14801 out of 17841\n",
      "loss: 1.9883828163146973, batch: 14851 out of 17841\n",
      "loss: 1.7357465028762817, batch: 14901 out of 17841\n",
      "loss: 1.8972690105438232, batch: 14951 out of 17841\n",
      "loss: 1.7647523880004883, batch: 15001 out of 17841\n",
      "loss: 1.9421749114990234, batch: 15051 out of 17841\n",
      "loss: 1.937178373336792, batch: 15101 out of 17841\n",
      "loss: 1.8627748489379883, batch: 15151 out of 17841\n",
      "loss: 1.6327674388885498, batch: 15201 out of 17841\n",
      "loss: 1.833770990371704, batch: 15251 out of 17841\n",
      "loss: 1.7744542360305786, batch: 15301 out of 17841\n",
      "loss: 1.9011363983154297, batch: 15351 out of 17841\n",
      "loss: 1.831032156944275, batch: 15401 out of 17841\n",
      "loss: 1.7526016235351562, batch: 15451 out of 17841\n",
      "loss: 1.7806475162506104, batch: 15501 out of 17841\n",
      "loss: 1.915395736694336, batch: 15551 out of 17841\n",
      "loss: 1.8957459926605225, batch: 15601 out of 17841\n",
      "loss: 1.7879438400268555, batch: 15651 out of 17841\n",
      "loss: 1.9661767482757568, batch: 15701 out of 17841\n",
      "loss: 1.8022923469543457, batch: 15751 out of 17841\n",
      "loss: 1.8701151609420776, batch: 15801 out of 17841\n",
      "loss: 1.7584927082061768, batch: 15851 out of 17841\n",
      "loss: 2.023491859436035, batch: 15901 out of 17841\n",
      "loss: 1.8602559566497803, batch: 15951 out of 17841\n",
      "loss: 1.9808565378189087, batch: 16001 out of 17841\n",
      "loss: 1.8155856132507324, batch: 16051 out of 17841\n",
      "loss: 1.7288445234298706, batch: 16101 out of 17841\n",
      "loss: 1.9772285223007202, batch: 16151 out of 17841\n",
      "loss: 1.8044185638427734, batch: 16201 out of 17841\n",
      "loss: 1.7073978185653687, batch: 16251 out of 17841\n",
      "loss: 1.6741974353790283, batch: 16301 out of 17841\n",
      "loss: 1.9953718185424805, batch: 16351 out of 17841\n",
      "loss: 1.870985746383667, batch: 16401 out of 17841\n",
      "loss: 1.9057636260986328, batch: 16451 out of 17841\n",
      "loss: 1.8958549499511719, batch: 16501 out of 17841\n",
      "loss: 1.9042510986328125, batch: 16551 out of 17841\n",
      "loss: 1.8656939268112183, batch: 16601 out of 17841\n",
      "loss: 1.912892460823059, batch: 16651 out of 17841\n",
      "loss: 1.9242539405822754, batch: 16701 out of 17841\n",
      "loss: 1.9373681545257568, batch: 16751 out of 17841\n",
      "loss: 1.6853604316711426, batch: 16801 out of 17841\n",
      "loss: 1.8493921756744385, batch: 16851 out of 17841\n",
      "loss: 1.7197582721710205, batch: 16901 out of 17841\n",
      "loss: 1.83551824092865, batch: 16951 out of 17841\n",
      "loss: 1.745849847793579, batch: 17001 out of 17841\n",
      "loss: 1.847904920578003, batch: 17051 out of 17841\n",
      "loss: 1.9319807291030884, batch: 17101 out of 17841\n",
      "loss: 1.8836499452590942, batch: 17151 out of 17841\n",
      "loss: 1.9101011753082275, batch: 17201 out of 17841\n",
      "loss: 1.8046867847442627, batch: 17251 out of 17841\n",
      "loss: 1.783434510231018, batch: 17301 out of 17841\n",
      "loss: 1.83382248878479, batch: 17351 out of 17841\n",
      "loss: 1.9696376323699951, batch: 17401 out of 17841\n",
      "loss: 1.8404035568237305, batch: 17451 out of 17841\n",
      "loss: 1.765071153640747, batch: 17501 out of 17841\n",
      "loss: 1.855746865272522, batch: 17551 out of 17841\n",
      "loss: 1.7513312101364136, batch: 17601 out of 17841\n",
      "loss: 1.9258028268814087, batch: 17651 out of 17841\n",
      "loss: 1.693579077720642, batch: 17701 out of 17841\n",
      "loss: 1.9063518047332764, batch: 17751 out of 17841\n",
      "loss: 1.9352855682373047, batch: 17801 out of 17841\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.7504013776779175, batch: 1 out of 17841\n",
      "loss: 1.8805932998657227, batch: 51 out of 17841\n",
      "loss: 1.813163161277771, batch: 101 out of 17841\n",
      "loss: 1.8178315162658691, batch: 151 out of 17841\n",
      "loss: 1.8389302492141724, batch: 201 out of 17841\n",
      "loss: 1.7722796201705933, batch: 251 out of 17841\n",
      "loss: 1.782036542892456, batch: 301 out of 17841\n",
      "loss: 1.8565022945404053, batch: 351 out of 17841\n",
      "loss: 1.7959290742874146, batch: 401 out of 17841\n",
      "loss: 1.836690902709961, batch: 451 out of 17841\n",
      "loss: 1.8418248891830444, batch: 501 out of 17841\n",
      "loss: 1.8132518529891968, batch: 551 out of 17841\n",
      "loss: 1.8959161043167114, batch: 601 out of 17841\n",
      "loss: 1.8741073608398438, batch: 651 out of 17841\n",
      "loss: 1.7065019607543945, batch: 701 out of 17841\n",
      "loss: 1.7642014026641846, batch: 751 out of 17841\n",
      "loss: 1.9241526126861572, batch: 801 out of 17841\n",
      "loss: 1.832984447479248, batch: 851 out of 17841\n",
      "loss: 1.952214241027832, batch: 901 out of 17841\n",
      "loss: 1.8048323392868042, batch: 951 out of 17841\n",
      "loss: 1.9192322492599487, batch: 1001 out of 17841\n",
      "loss: 1.756379246711731, batch: 1051 out of 17841\n",
      "loss: 1.8448774814605713, batch: 1101 out of 17841\n",
      "loss: 1.8716979026794434, batch: 1151 out of 17841\n",
      "loss: 1.860137701034546, batch: 1201 out of 17841\n",
      "loss: 1.7397112846374512, batch: 1251 out of 17841\n",
      "loss: 1.801804780960083, batch: 1301 out of 17841\n",
      "loss: 1.8259999752044678, batch: 1351 out of 17841\n",
      "loss: 1.794161319732666, batch: 1401 out of 17841\n",
      "loss: 1.836406946182251, batch: 1451 out of 17841\n",
      "loss: 1.8407801389694214, batch: 1501 out of 17841\n",
      "loss: 1.9515970945358276, batch: 1551 out of 17841\n",
      "loss: 1.7529256343841553, batch: 1601 out of 17841\n",
      "loss: 1.7731573581695557, batch: 1651 out of 17841\n",
      "loss: 1.682562232017517, batch: 1701 out of 17841\n",
      "loss: 1.813259243965149, batch: 1751 out of 17841\n",
      "loss: 1.9527826309204102, batch: 1801 out of 17841\n",
      "loss: 1.7261981964111328, batch: 1851 out of 17841\n",
      "loss: 1.9172852039337158, batch: 1901 out of 17841\n",
      "loss: 1.6857585906982422, batch: 1951 out of 17841\n",
      "loss: 1.875296711921692, batch: 2001 out of 17841\n",
      "loss: 1.8275058269500732, batch: 2051 out of 17841\n",
      "loss: 1.8590316772460938, batch: 2101 out of 17841\n",
      "loss: 1.7810193300247192, batch: 2151 out of 17841\n",
      "loss: 1.7555897235870361, batch: 2201 out of 17841\n",
      "loss: 1.8579425811767578, batch: 2251 out of 17841\n",
      "loss: 1.8961966037750244, batch: 2301 out of 17841\n",
      "loss: 1.8044424057006836, batch: 2351 out of 17841\n",
      "loss: 1.7585711479187012, batch: 2401 out of 17841\n",
      "loss: 1.764582872390747, batch: 2451 out of 17841\n",
      "loss: 1.9581389427185059, batch: 2501 out of 17841\n",
      "loss: 1.7812068462371826, batch: 2551 out of 17841\n",
      "loss: 1.816078782081604, batch: 2601 out of 17841\n",
      "loss: 1.746462106704712, batch: 2651 out of 17841\n",
      "loss: 1.818098545074463, batch: 2701 out of 17841\n",
      "loss: 1.7509050369262695, batch: 2751 out of 17841\n",
      "loss: 1.8595324754714966, batch: 2801 out of 17841\n",
      "loss: 1.8493731021881104, batch: 2851 out of 17841\n",
      "loss: 1.6944169998168945, batch: 2901 out of 17841\n",
      "loss: 1.8155083656311035, batch: 2951 out of 17841\n",
      "loss: 1.905813217163086, batch: 3001 out of 17841\n",
      "loss: 1.7685823440551758, batch: 3051 out of 17841\n",
      "loss: 1.813770055770874, batch: 3101 out of 17841\n",
      "loss: 1.7997493743896484, batch: 3151 out of 17841\n",
      "loss: 1.8757810592651367, batch: 3201 out of 17841\n",
      "loss: 1.8831827640533447, batch: 3251 out of 17841\n",
      "loss: 1.9088773727416992, batch: 3301 out of 17841\n",
      "loss: 1.7863340377807617, batch: 3351 out of 17841\n",
      "loss: 1.7620277404785156, batch: 3401 out of 17841\n",
      "loss: 1.9805221557617188, batch: 3451 out of 17841\n",
      "loss: 1.833182454109192, batch: 3501 out of 17841\n",
      "loss: 1.9250929355621338, batch: 3551 out of 17841\n",
      "loss: 1.7453389167785645, batch: 3601 out of 17841\n",
      "loss: 1.896604061126709, batch: 3651 out of 17841\n",
      "loss: 1.7571425437927246, batch: 3701 out of 17841\n",
      "loss: 1.7847181558609009, batch: 3751 out of 17841\n",
      "loss: 1.7608262300491333, batch: 3801 out of 17841\n",
      "loss: 1.8583488464355469, batch: 3851 out of 17841\n",
      "loss: 1.8082976341247559, batch: 3901 out of 17841\n",
      "loss: 1.8736546039581299, batch: 3951 out of 17841\n",
      "loss: 1.9181201457977295, batch: 4001 out of 17841\n",
      "loss: 1.8420958518981934, batch: 4051 out of 17841\n",
      "loss: 1.887619972229004, batch: 4101 out of 17841\n",
      "loss: 1.7707314491271973, batch: 4151 out of 17841\n",
      "loss: 1.7824259996414185, batch: 4201 out of 17841\n",
      "loss: 1.7098002433776855, batch: 4251 out of 17841\n",
      "loss: 1.8387013673782349, batch: 4301 out of 17841\n",
      "loss: 1.878040075302124, batch: 4351 out of 17841\n",
      "loss: 1.7241921424865723, batch: 4401 out of 17841\n",
      "loss: 1.7522486448287964, batch: 4451 out of 17841\n",
      "loss: 1.7978936433792114, batch: 4501 out of 17841\n",
      "loss: 1.840575933456421, batch: 4551 out of 17841\n",
      "loss: 1.8591699600219727, batch: 4601 out of 17841\n",
      "loss: 1.8404691219329834, batch: 4651 out of 17841\n",
      "loss: 1.7844222784042358, batch: 4701 out of 17841\n",
      "loss: 1.9076740741729736, batch: 4751 out of 17841\n",
      "loss: 1.7766492366790771, batch: 4801 out of 17841\n",
      "loss: 1.915461540222168, batch: 4851 out of 17841\n",
      "loss: 1.9040429592132568, batch: 4901 out of 17841\n",
      "loss: 1.8646388053894043, batch: 4951 out of 17841\n",
      "loss: 1.8249335289001465, batch: 5001 out of 17841\n",
      "loss: 1.8131113052368164, batch: 5051 out of 17841\n",
      "loss: 1.847814917564392, batch: 5101 out of 17841\n",
      "loss: 1.7942078113555908, batch: 5151 out of 17841\n",
      "loss: 1.7257442474365234, batch: 5201 out of 17841\n",
      "loss: 2.010169506072998, batch: 5251 out of 17841\n",
      "loss: 1.6938178539276123, batch: 5301 out of 17841\n",
      "loss: 1.88344407081604, batch: 5351 out of 17841\n",
      "loss: 1.7395087480545044, batch: 5401 out of 17841\n",
      "loss: 1.8341689109802246, batch: 5451 out of 17841\n",
      "loss: 1.7777966260910034, batch: 5501 out of 17841\n",
      "loss: 1.8511321544647217, batch: 5551 out of 17841\n",
      "loss: 1.8857247829437256, batch: 5601 out of 17841\n",
      "loss: 1.9987971782684326, batch: 5651 out of 17841\n",
      "loss: 1.8171403408050537, batch: 5701 out of 17841\n",
      "loss: 1.7309632301330566, batch: 5751 out of 17841\n",
      "loss: 1.6919519901275635, batch: 5801 out of 17841\n",
      "loss: 1.8594183921813965, batch: 5851 out of 17841\n",
      "loss: 1.7718489170074463, batch: 5901 out of 17841\n",
      "loss: 1.8336546421051025, batch: 5951 out of 17841\n",
      "loss: 1.958688497543335, batch: 6001 out of 17841\n",
      "loss: 1.9912434816360474, batch: 6051 out of 17841\n",
      "loss: 1.9066985845565796, batch: 6101 out of 17841\n",
      "loss: 1.7792589664459229, batch: 6151 out of 17841\n",
      "loss: 1.8956949710845947, batch: 6201 out of 17841\n",
      "loss: 1.8959468603134155, batch: 6251 out of 17841\n",
      "loss: 1.7195004224777222, batch: 6301 out of 17841\n",
      "loss: 2.0064196586608887, batch: 6351 out of 17841\n",
      "loss: 1.916337490081787, batch: 6401 out of 17841\n",
      "loss: 1.7712770700454712, batch: 6451 out of 17841\n",
      "loss: 1.7055599689483643, batch: 6501 out of 17841\n",
      "loss: 1.6628503799438477, batch: 6551 out of 17841\n",
      "loss: 1.8228777647018433, batch: 6601 out of 17841\n",
      "loss: 1.8396620750427246, batch: 6651 out of 17841\n",
      "loss: 1.9379185438156128, batch: 6701 out of 17841\n",
      "loss: 1.727020025253296, batch: 6751 out of 17841\n",
      "loss: 1.7568141222000122, batch: 6801 out of 17841\n",
      "loss: 1.693974256515503, batch: 6851 out of 17841\n",
      "loss: 1.98740816116333, batch: 6901 out of 17841\n",
      "loss: 1.9215891361236572, batch: 6951 out of 17841\n",
      "loss: 1.8866236209869385, batch: 7001 out of 17841\n",
      "loss: 1.7526326179504395, batch: 7051 out of 17841\n",
      "loss: 1.8881384134292603, batch: 7101 out of 17841\n",
      "loss: 1.830545425415039, batch: 7151 out of 17841\n",
      "loss: 1.793837308883667, batch: 7201 out of 17841\n",
      "loss: 1.5885045528411865, batch: 7251 out of 17841\n",
      "loss: 1.8930120468139648, batch: 7301 out of 17841\n",
      "loss: 1.844592809677124, batch: 7351 out of 17841\n",
      "loss: 1.8688652515411377, batch: 7401 out of 17841\n",
      "loss: 1.7372016906738281, batch: 7451 out of 17841\n",
      "loss: 1.882540225982666, batch: 7501 out of 17841\n",
      "loss: 1.6204874515533447, batch: 7551 out of 17841\n",
      "loss: 1.7077679634094238, batch: 7601 out of 17841\n",
      "loss: 1.789550542831421, batch: 7651 out of 17841\n",
      "loss: 1.844190001487732, batch: 7701 out of 17841\n",
      "loss: 1.819103717803955, batch: 7751 out of 17841\n",
      "loss: 1.8284823894500732, batch: 7801 out of 17841\n",
      "loss: 1.773956060409546, batch: 7851 out of 17841\n",
      "loss: 1.8083887100219727, batch: 7901 out of 17841\n",
      "loss: 1.764810562133789, batch: 7951 out of 17841\n",
      "loss: 1.661560297012329, batch: 8001 out of 17841\n",
      "loss: 1.9346356391906738, batch: 8051 out of 17841\n",
      "loss: 1.7744848728179932, batch: 8101 out of 17841\n",
      "loss: 1.8889349699020386, batch: 8151 out of 17841\n",
      "loss: 2.0323784351348877, batch: 8201 out of 17841\n",
      "loss: 1.8587597608566284, batch: 8251 out of 17841\n",
      "loss: 1.8579480648040771, batch: 8301 out of 17841\n",
      "loss: 1.8870389461517334, batch: 8351 out of 17841\n",
      "loss: 1.7221297025680542, batch: 8401 out of 17841\n",
      "loss: 1.8639204502105713, batch: 8451 out of 17841\n",
      "loss: 1.8793666362762451, batch: 8501 out of 17841\n",
      "loss: 1.8176398277282715, batch: 8551 out of 17841\n",
      "loss: 1.8451502323150635, batch: 8601 out of 17841\n",
      "loss: 1.7811753749847412, batch: 8651 out of 17841\n",
      "loss: 1.8068921566009521, batch: 8701 out of 17841\n",
      "loss: 1.7945120334625244, batch: 8751 out of 17841\n",
      "loss: 1.7698894739151, batch: 8801 out of 17841\n",
      "loss: 1.806171178817749, batch: 8851 out of 17841\n",
      "loss: 1.7272001504898071, batch: 8901 out of 17841\n",
      "loss: 1.858002781867981, batch: 8951 out of 17841\n",
      "loss: 1.7127360105514526, batch: 9001 out of 17841\n",
      "loss: 1.864210605621338, batch: 9051 out of 17841\n",
      "loss: 1.7378487586975098, batch: 9101 out of 17841\n",
      "loss: 1.830631136894226, batch: 9151 out of 17841\n",
      "loss: 1.7479848861694336, batch: 9201 out of 17841\n",
      "loss: 1.8538634777069092, batch: 9251 out of 17841\n",
      "loss: 1.7412183284759521, batch: 9301 out of 17841\n",
      "loss: 1.7932484149932861, batch: 9351 out of 17841\n",
      "loss: 1.8753889799118042, batch: 9401 out of 17841\n",
      "loss: 1.8251938819885254, batch: 9451 out of 17841\n",
      "loss: 1.842223882675171, batch: 9501 out of 17841\n",
      "loss: 1.8693714141845703, batch: 9551 out of 17841\n",
      "loss: 1.779675006866455, batch: 9601 out of 17841\n",
      "loss: 1.815203309059143, batch: 9651 out of 17841\n",
      "loss: 1.8735747337341309, batch: 9701 out of 17841\n",
      "loss: 1.8079239130020142, batch: 9751 out of 17841\n",
      "loss: 1.8445260524749756, batch: 9801 out of 17841\n",
      "loss: 1.842480182647705, batch: 9851 out of 17841\n",
      "loss: 1.8396096229553223, batch: 9901 out of 17841\n",
      "loss: 1.9789460897445679, batch: 9951 out of 17841\n",
      "loss: 1.8655874729156494, batch: 10001 out of 17841\n",
      "loss: 1.7886769771575928, batch: 10051 out of 17841\n",
      "loss: 1.6993968486785889, batch: 10101 out of 17841\n",
      "loss: 1.807244896888733, batch: 10151 out of 17841\n",
      "loss: 1.7356693744659424, batch: 10201 out of 17841\n",
      "loss: 1.8371483087539673, batch: 10251 out of 17841\n",
      "loss: 1.9397907257080078, batch: 10301 out of 17841\n",
      "loss: 1.7149302959442139, batch: 10351 out of 17841\n",
      "loss: 1.669500470161438, batch: 10401 out of 17841\n",
      "loss: 1.8394849300384521, batch: 10451 out of 17841\n",
      "loss: 1.837233543395996, batch: 10501 out of 17841\n",
      "loss: 1.8120040893554688, batch: 10551 out of 17841\n",
      "loss: 1.783218502998352, batch: 10601 out of 17841\n",
      "loss: 1.9157001972198486, batch: 10651 out of 17841\n",
      "loss: 1.863274335861206, batch: 10701 out of 17841\n",
      "loss: 1.8337783813476562, batch: 10751 out of 17841\n",
      "loss: 1.9312400817871094, batch: 10801 out of 17841\n",
      "loss: 1.7500789165496826, batch: 10851 out of 17841\n",
      "loss: 1.7019929885864258, batch: 10901 out of 17841\n",
      "loss: 1.8473577499389648, batch: 10951 out of 17841\n",
      "loss: 1.86075758934021, batch: 11001 out of 17841\n",
      "loss: 1.7790207862854004, batch: 11051 out of 17841\n",
      "loss: 1.8870514631271362, batch: 11101 out of 17841\n",
      "loss: 1.8029403686523438, batch: 11151 out of 17841\n",
      "loss: 1.7610011100769043, batch: 11201 out of 17841\n",
      "loss: 1.904330849647522, batch: 11251 out of 17841\n",
      "loss: 1.8390265703201294, batch: 11301 out of 17841\n",
      "loss: 1.7696623802185059, batch: 11351 out of 17841\n",
      "loss: 1.8282661437988281, batch: 11401 out of 17841\n",
      "loss: 1.776094675064087, batch: 11451 out of 17841\n",
      "loss: 1.766066312789917, batch: 11501 out of 17841\n",
      "loss: 1.8917006254196167, batch: 11551 out of 17841\n",
      "loss: 1.8441226482391357, batch: 11601 out of 17841\n",
      "loss: 1.7548773288726807, batch: 11651 out of 17841\n",
      "loss: 1.924561858177185, batch: 11701 out of 17841\n",
      "loss: 1.9018323421478271, batch: 11751 out of 17841\n",
      "loss: 1.8362981081008911, batch: 11801 out of 17841\n",
      "loss: 1.753011703491211, batch: 11851 out of 17841\n",
      "loss: 1.7248094081878662, batch: 11901 out of 17841\n",
      "loss: 1.773101806640625, batch: 11951 out of 17841\n",
      "loss: 1.6988294124603271, batch: 12001 out of 17841\n",
      "loss: 1.798450231552124, batch: 12051 out of 17841\n",
      "loss: 1.6464111804962158, batch: 12101 out of 17841\n",
      "loss: 1.7910568714141846, batch: 12151 out of 17841\n",
      "loss: 1.7795296907424927, batch: 12201 out of 17841\n",
      "loss: 1.7487884759902954, batch: 12251 out of 17841\n",
      "loss: 1.8329874277114868, batch: 12301 out of 17841\n",
      "loss: 1.851959228515625, batch: 12351 out of 17841\n",
      "loss: 1.7788918018341064, batch: 12401 out of 17841\n",
      "loss: 1.7408299446105957, batch: 12451 out of 17841\n",
      "loss: 1.868786334991455, batch: 12501 out of 17841\n",
      "loss: 1.8031213283538818, batch: 12551 out of 17841\n",
      "loss: 1.7711820602416992, batch: 12601 out of 17841\n",
      "loss: 1.7923955917358398, batch: 12651 out of 17841\n",
      "loss: 1.7229437828063965, batch: 12701 out of 17841\n",
      "loss: 1.8967348337173462, batch: 12751 out of 17841\n",
      "loss: 1.8741998672485352, batch: 12801 out of 17841\n",
      "loss: 1.8399406671524048, batch: 12851 out of 17841\n",
      "loss: 1.7684624195098877, batch: 12901 out of 17841\n",
      "loss: 1.8461172580718994, batch: 12951 out of 17841\n",
      "loss: 1.785447597503662, batch: 13001 out of 17841\n",
      "loss: 1.8520586490631104, batch: 13051 out of 17841\n",
      "loss: 1.855886459350586, batch: 13101 out of 17841\n",
      "loss: 1.701974630355835, batch: 13151 out of 17841\n",
      "loss: 1.7084364891052246, batch: 13201 out of 17841\n",
      "loss: 1.8168237209320068, batch: 13251 out of 17841\n",
      "loss: 1.7848589420318604, batch: 13301 out of 17841\n",
      "loss: 1.7786369323730469, batch: 13351 out of 17841\n",
      "loss: 1.7230207920074463, batch: 13401 out of 17841\n",
      "loss: 1.820589542388916, batch: 13451 out of 17841\n",
      "loss: 1.8005573749542236, batch: 13501 out of 17841\n",
      "loss: 1.8378980159759521, batch: 13551 out of 17841\n",
      "loss: 1.7171785831451416, batch: 13601 out of 17841\n",
      "loss: 1.877116322517395, batch: 13651 out of 17841\n",
      "loss: 1.9551403522491455, batch: 13701 out of 17841\n",
      "loss: 1.7719428539276123, batch: 13751 out of 17841\n",
      "loss: 1.9181665182113647, batch: 13801 out of 17841\n",
      "loss: 1.6716357469558716, batch: 13851 out of 17841\n",
      "loss: 1.9224863052368164, batch: 13901 out of 17841\n",
      "loss: 1.7512648105621338, batch: 13951 out of 17841\n",
      "loss: 1.7271376848220825, batch: 14001 out of 17841\n",
      "loss: 1.968320369720459, batch: 14051 out of 17841\n",
      "loss: 1.8440818786621094, batch: 14101 out of 17841\n",
      "loss: 1.920151948928833, batch: 14151 out of 17841\n",
      "loss: 1.6819688081741333, batch: 14201 out of 17841\n",
      "loss: 1.814154028892517, batch: 14251 out of 17841\n",
      "loss: 1.625901222229004, batch: 14301 out of 17841\n",
      "loss: 1.8364732265472412, batch: 14351 out of 17841\n",
      "loss: 1.9905962944030762, batch: 14401 out of 17841\n",
      "loss: 1.7742544412612915, batch: 14451 out of 17841\n",
      "loss: 1.7972499132156372, batch: 14501 out of 17841\n",
      "loss: 1.6890206336975098, batch: 14551 out of 17841\n",
      "loss: 1.8235607147216797, batch: 14601 out of 17841\n",
      "loss: 1.8566480875015259, batch: 14651 out of 17841\n",
      "loss: 1.9732367992401123, batch: 14701 out of 17841\n",
      "loss: 1.868646264076233, batch: 14751 out of 17841\n",
      "loss: 1.8388671875, batch: 14801 out of 17841\n",
      "loss: 1.8298934698104858, batch: 14851 out of 17841\n",
      "loss: 1.8945693969726562, batch: 14901 out of 17841\n",
      "loss: 1.8377788066864014, batch: 14951 out of 17841\n",
      "loss: 1.8289642333984375, batch: 15001 out of 17841\n",
      "loss: 1.824366807937622, batch: 15051 out of 17841\n",
      "loss: 1.71339750289917, batch: 15101 out of 17841\n",
      "loss: 1.8205246925354004, batch: 15151 out of 17841\n",
      "loss: 1.7655718326568604, batch: 15201 out of 17841\n",
      "loss: 1.9281121492385864, batch: 15251 out of 17841\n",
      "loss: 1.8351407051086426, batch: 15301 out of 17841\n",
      "loss: 1.8317878246307373, batch: 15351 out of 17841\n",
      "loss: 1.632596731185913, batch: 15401 out of 17841\n",
      "loss: 1.6804225444793701, batch: 15451 out of 17841\n",
      "loss: 1.8200485706329346, batch: 15501 out of 17841\n",
      "loss: 1.7752724885940552, batch: 15551 out of 17841\n",
      "loss: 1.767391324043274, batch: 15601 out of 17841\n",
      "loss: 2.04119873046875, batch: 15651 out of 17841\n",
      "loss: 1.928536295890808, batch: 15701 out of 17841\n",
      "loss: 1.7728402614593506, batch: 15751 out of 17841\n",
      "loss: 1.8371734619140625, batch: 15801 out of 17841\n",
      "loss: 1.7615183591842651, batch: 15851 out of 17841\n",
      "loss: 1.7249751091003418, batch: 15901 out of 17841\n",
      "loss: 1.810513973236084, batch: 15951 out of 17841\n",
      "loss: 1.758424997329712, batch: 16001 out of 17841\n",
      "loss: 1.876530647277832, batch: 16051 out of 17841\n",
      "loss: 1.8259894847869873, batch: 16101 out of 17841\n",
      "loss: 1.7214415073394775, batch: 16151 out of 17841\n",
      "loss: 1.7678453922271729, batch: 16201 out of 17841\n",
      "loss: 1.8461589813232422, batch: 16251 out of 17841\n",
      "loss: 1.891920566558838, batch: 16301 out of 17841\n",
      "loss: 1.864670991897583, batch: 16351 out of 17841\n",
      "loss: 1.8150858879089355, batch: 16401 out of 17841\n",
      "loss: 1.78324556350708, batch: 16451 out of 17841\n",
      "loss: 1.7708754539489746, batch: 16501 out of 17841\n",
      "loss: 1.8625750541687012, batch: 16551 out of 17841\n",
      "loss: 1.6756731271743774, batch: 16601 out of 17841\n",
      "loss: 1.7563514709472656, batch: 16651 out of 17841\n",
      "loss: 1.8475518226623535, batch: 16701 out of 17841\n",
      "loss: 1.8468769788742065, batch: 16751 out of 17841\n",
      "loss: 1.8023040294647217, batch: 16801 out of 17841\n",
      "loss: 1.9115058183670044, batch: 16851 out of 17841\n",
      "loss: 1.713506817817688, batch: 16901 out of 17841\n",
      "loss: 1.8172305822372437, batch: 16951 out of 17841\n",
      "loss: 1.8152358531951904, batch: 17001 out of 17841\n",
      "loss: 1.8363556861877441, batch: 17051 out of 17841\n",
      "loss: 1.7743830680847168, batch: 17101 out of 17841\n",
      "loss: 1.7553174495697021, batch: 17151 out of 17841\n",
      "loss: 1.8040766716003418, batch: 17201 out of 17841\n",
      "loss: 1.7895472049713135, batch: 17251 out of 17841\n",
      "loss: 1.6919968128204346, batch: 17301 out of 17841\n",
      "loss: 1.9151502847671509, batch: 17351 out of 17841\n",
      "loss: 1.9083430767059326, batch: 17401 out of 17841\n",
      "loss: 1.711683750152588, batch: 17451 out of 17841\n",
      "loss: 1.8918253183364868, batch: 17501 out of 17841\n",
      "loss: 1.7739883661270142, batch: 17551 out of 17841\n",
      "loss: 1.6846904754638672, batch: 17601 out of 17841\n",
      "loss: 1.7440688610076904, batch: 17651 out of 17841\n",
      "loss: 1.7808887958526611, batch: 17701 out of 17841\n",
      "loss: 1.8077412843704224, batch: 17751 out of 17841\n",
      "loss: 1.8926935195922852, batch: 17801 out of 17841\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.9024076461791992, batch: 1 out of 17841\n",
      "loss: 1.844800591468811, batch: 51 out of 17841\n",
      "loss: 1.7657346725463867, batch: 101 out of 17841\n",
      "loss: 1.8751702308654785, batch: 151 out of 17841\n",
      "loss: 1.7712231874465942, batch: 201 out of 17841\n",
      "loss: 1.8891544342041016, batch: 251 out of 17841\n",
      "loss: 1.804776668548584, batch: 301 out of 17841\n",
      "loss: 1.8723692893981934, batch: 351 out of 17841\n",
      "loss: 1.6451342105865479, batch: 401 out of 17841\n",
      "loss: 1.6231110095977783, batch: 451 out of 17841\n",
      "loss: 1.8669145107269287, batch: 501 out of 17841\n",
      "loss: 1.6724655628204346, batch: 551 out of 17841\n",
      "loss: 1.7830510139465332, batch: 601 out of 17841\n",
      "loss: 1.9054752588272095, batch: 651 out of 17841\n",
      "loss: 1.9589900970458984, batch: 701 out of 17841\n",
      "loss: 1.7093620300292969, batch: 751 out of 17841\n",
      "loss: 1.7018663883209229, batch: 801 out of 17841\n",
      "loss: 1.706890344619751, batch: 851 out of 17841\n",
      "loss: 1.9346895217895508, batch: 901 out of 17841\n",
      "loss: 1.707944393157959, batch: 951 out of 17841\n",
      "loss: 1.787076711654663, batch: 1001 out of 17841\n",
      "loss: 1.701753854751587, batch: 1051 out of 17841\n",
      "loss: 1.8308124542236328, batch: 1101 out of 17841\n",
      "loss: 1.9633779525756836, batch: 1151 out of 17841\n",
      "loss: 1.795912504196167, batch: 1201 out of 17841\n",
      "loss: 1.870648980140686, batch: 1251 out of 17841\n",
      "loss: 1.868863821029663, batch: 1301 out of 17841\n",
      "loss: 1.9064068794250488, batch: 1351 out of 17841\n",
      "loss: 1.7458707094192505, batch: 1401 out of 17841\n",
      "loss: 1.7300002574920654, batch: 1451 out of 17841\n",
      "loss: 1.8347758054733276, batch: 1501 out of 17841\n",
      "loss: 1.870518445968628, batch: 1551 out of 17841\n",
      "loss: 1.7777718305587769, batch: 1601 out of 17841\n",
      "loss: 1.765916109085083, batch: 1651 out of 17841\n",
      "loss: 1.9195376634597778, batch: 1701 out of 17841\n",
      "loss: 1.871065616607666, batch: 1751 out of 17841\n",
      "loss: 1.7720472812652588, batch: 1801 out of 17841\n",
      "loss: 1.798400640487671, batch: 1851 out of 17841\n",
      "loss: 1.7760266065597534, batch: 1901 out of 17841\n",
      "loss: 1.7713608741760254, batch: 1951 out of 17841\n",
      "loss: 1.8679393529891968, batch: 2001 out of 17841\n",
      "loss: 1.7309849262237549, batch: 2051 out of 17841\n",
      "loss: 1.8906328678131104, batch: 2101 out of 17841\n",
      "loss: 1.7890926599502563, batch: 2151 out of 17841\n",
      "loss: 1.7872116565704346, batch: 2201 out of 17841\n",
      "loss: 1.9098831415176392, batch: 2251 out of 17841\n",
      "loss: 1.8626043796539307, batch: 2301 out of 17841\n",
      "loss: 1.9267734289169312, batch: 2351 out of 17841\n",
      "loss: 1.8408071994781494, batch: 2401 out of 17841\n",
      "loss: 1.8791321516036987, batch: 2451 out of 17841\n",
      "loss: 1.7726788520812988, batch: 2501 out of 17841\n",
      "loss: 1.8368064165115356, batch: 2551 out of 17841\n",
      "loss: 1.9396132230758667, batch: 2601 out of 17841\n",
      "loss: 1.9461342096328735, batch: 2651 out of 17841\n",
      "loss: 1.828000783920288, batch: 2701 out of 17841\n",
      "loss: 1.8868377208709717, batch: 2751 out of 17841\n",
      "loss: 1.7715275287628174, batch: 2801 out of 17841\n",
      "loss: 1.694962978363037, batch: 2851 out of 17841\n",
      "loss: 1.7968809604644775, batch: 2901 out of 17841\n",
      "loss: 1.8257768154144287, batch: 2951 out of 17841\n",
      "loss: 1.8189892768859863, batch: 3001 out of 17841\n",
      "loss: 1.8772209882736206, batch: 3051 out of 17841\n",
      "loss: 1.7648502588272095, batch: 3101 out of 17841\n",
      "loss: 1.780932903289795, batch: 3151 out of 17841\n",
      "loss: 1.7605102062225342, batch: 3201 out of 17841\n",
      "loss: 1.8655261993408203, batch: 3251 out of 17841\n",
      "loss: 1.9098131656646729, batch: 3301 out of 17841\n",
      "loss: 1.861792802810669, batch: 3351 out of 17841\n",
      "loss: 1.9301495552062988, batch: 3401 out of 17841\n",
      "loss: 1.767960786819458, batch: 3451 out of 17841\n",
      "loss: 1.8338638544082642, batch: 3501 out of 17841\n",
      "loss: 1.7478139400482178, batch: 3551 out of 17841\n",
      "loss: 1.8562443256378174, batch: 3601 out of 17841\n",
      "loss: 1.7153791189193726, batch: 3651 out of 17841\n",
      "loss: 1.7948095798492432, batch: 3701 out of 17841\n",
      "loss: 1.88569176197052, batch: 3751 out of 17841\n",
      "loss: 1.8636796474456787, batch: 3801 out of 17841\n",
      "loss: 1.9275513887405396, batch: 3851 out of 17841\n",
      "loss: 1.7948005199432373, batch: 3901 out of 17841\n",
      "loss: 1.7902922630310059, batch: 3951 out of 17841\n",
      "loss: 1.8374934196472168, batch: 4001 out of 17841\n",
      "loss: 1.7315936088562012, batch: 4051 out of 17841\n",
      "loss: 1.9633866548538208, batch: 4101 out of 17841\n",
      "loss: 1.7920475006103516, batch: 4151 out of 17841\n",
      "loss: 1.9842145442962646, batch: 4201 out of 17841\n",
      "loss: 1.832798957824707, batch: 4251 out of 17841\n",
      "loss: 1.7814202308654785, batch: 4301 out of 17841\n",
      "loss: 1.7446660995483398, batch: 4351 out of 17841\n",
      "loss: 1.7646209001541138, batch: 4401 out of 17841\n",
      "loss: 1.778367042541504, batch: 4451 out of 17841\n",
      "loss: 1.8110308647155762, batch: 4501 out of 17841\n",
      "loss: 1.6502317190170288, batch: 4551 out of 17841\n",
      "loss: 1.736130952835083, batch: 4601 out of 17841\n",
      "loss: 1.778038501739502, batch: 4651 out of 17841\n",
      "loss: 1.8513072729110718, batch: 4701 out of 17841\n",
      "loss: 1.8356497287750244, batch: 4751 out of 17841\n",
      "loss: 1.8488273620605469, batch: 4801 out of 17841\n",
      "loss: 1.6933393478393555, batch: 4851 out of 17841\n",
      "loss: 1.808950662612915, batch: 4901 out of 17841\n",
      "loss: 1.8172473907470703, batch: 4951 out of 17841\n",
      "loss: 1.7997205257415771, batch: 5001 out of 17841\n",
      "loss: 1.9073482751846313, batch: 5051 out of 17841\n",
      "loss: 2.0179226398468018, batch: 5101 out of 17841\n",
      "loss: 1.8904112577438354, batch: 5151 out of 17841\n",
      "loss: 1.6520549058914185, batch: 5201 out of 17841\n",
      "loss: 1.878495454788208, batch: 5251 out of 17841\n",
      "loss: 1.656959891319275, batch: 5301 out of 17841\n",
      "loss: 1.730125904083252, batch: 5351 out of 17841\n",
      "loss: 1.8799073696136475, batch: 5401 out of 17841\n",
      "loss: 1.725278615951538, batch: 5451 out of 17841\n",
      "loss: 1.8092162609100342, batch: 5501 out of 17841\n",
      "loss: 1.815894365310669, batch: 5551 out of 17841\n",
      "loss: 1.6902358531951904, batch: 5601 out of 17841\n",
      "loss: 1.8385405540466309, batch: 5651 out of 17841\n",
      "loss: 1.7784857749938965, batch: 5701 out of 17841\n",
      "loss: 1.8046798706054688, batch: 5751 out of 17841\n",
      "loss: 1.8523954153060913, batch: 5801 out of 17841\n",
      "loss: 1.9674649238586426, batch: 5851 out of 17841\n",
      "loss: 1.7867145538330078, batch: 5901 out of 17841\n",
      "loss: 1.8145451545715332, batch: 5951 out of 17841\n",
      "loss: 1.834625005722046, batch: 6001 out of 17841\n",
      "loss: 1.7822258472442627, batch: 6051 out of 17841\n",
      "loss: 1.9237208366394043, batch: 6101 out of 17841\n",
      "loss: 1.9043971300125122, batch: 6151 out of 17841\n",
      "loss: 1.804040789604187, batch: 6201 out of 17841\n",
      "loss: 1.9425723552703857, batch: 6251 out of 17841\n",
      "loss: 1.764909029006958, batch: 6301 out of 17841\n",
      "loss: 1.8180266618728638, batch: 6351 out of 17841\n",
      "loss: 1.869523525238037, batch: 6401 out of 17841\n",
      "loss: 1.7246224880218506, batch: 6451 out of 17841\n",
      "loss: 1.8923776149749756, batch: 6501 out of 17841\n",
      "loss: 1.9232103824615479, batch: 6551 out of 17841\n",
      "loss: 1.9649282693862915, batch: 6601 out of 17841\n",
      "loss: 1.761843204498291, batch: 6651 out of 17841\n",
      "loss: 1.7531368732452393, batch: 6701 out of 17841\n",
      "loss: 1.8445079326629639, batch: 6751 out of 17841\n",
      "loss: 1.8679753541946411, batch: 6801 out of 17841\n",
      "loss: 1.88234281539917, batch: 6851 out of 17841\n",
      "loss: 1.7732566595077515, batch: 6901 out of 17841\n",
      "loss: 1.8517714738845825, batch: 6951 out of 17841\n",
      "loss: 1.797152042388916, batch: 7001 out of 17841\n",
      "loss: 1.6379969120025635, batch: 7051 out of 17841\n",
      "loss: 1.8506810665130615, batch: 7101 out of 17841\n",
      "loss: 1.816189169883728, batch: 7151 out of 17841\n",
      "loss: 1.7546831369400024, batch: 7201 out of 17841\n",
      "loss: 1.782967448234558, batch: 7251 out of 17841\n",
      "loss: 1.7995394468307495, batch: 7301 out of 17841\n",
      "loss: 1.7215347290039062, batch: 7351 out of 17841\n",
      "loss: 1.7876490354537964, batch: 7401 out of 17841\n",
      "loss: 1.782327651977539, batch: 7451 out of 17841\n",
      "loss: 1.9068872928619385, batch: 7501 out of 17841\n",
      "loss: 1.7085915803909302, batch: 7551 out of 17841\n",
      "loss: 1.86509370803833, batch: 7601 out of 17841\n",
      "loss: 1.8394672870635986, batch: 7651 out of 17841\n",
      "loss: 1.6940536499023438, batch: 7701 out of 17841\n",
      "loss: 1.8166255950927734, batch: 7751 out of 17841\n",
      "loss: 1.8394267559051514, batch: 7801 out of 17841\n",
      "loss: 1.811500072479248, batch: 7851 out of 17841\n",
      "loss: 1.7785732746124268, batch: 7901 out of 17841\n",
      "loss: 1.7860935926437378, batch: 7951 out of 17841\n",
      "loss: 1.8580968379974365, batch: 8001 out of 17841\n",
      "loss: 1.7453187704086304, batch: 8051 out of 17841\n",
      "loss: 1.8375110626220703, batch: 8101 out of 17841\n",
      "loss: 1.9291257858276367, batch: 8151 out of 17841\n",
      "loss: 1.8521976470947266, batch: 8201 out of 17841\n",
      "loss: 1.8957114219665527, batch: 8251 out of 17841\n",
      "loss: 1.9443659782409668, batch: 8301 out of 17841\n",
      "loss: 1.778357744216919, batch: 8351 out of 17841\n",
      "loss: 1.9695838689804077, batch: 8401 out of 17841\n",
      "loss: 1.7383137941360474, batch: 8451 out of 17841\n",
      "loss: 1.8724548816680908, batch: 8501 out of 17841\n",
      "loss: 1.8516380786895752, batch: 8551 out of 17841\n",
      "loss: 1.8793766498565674, batch: 8601 out of 17841\n",
      "loss: 1.7909067869186401, batch: 8651 out of 17841\n",
      "loss: 1.8402243852615356, batch: 8701 out of 17841\n",
      "loss: 1.8597967624664307, batch: 8751 out of 17841\n",
      "loss: 1.847809076309204, batch: 8801 out of 17841\n",
      "loss: 1.9205811023712158, batch: 8851 out of 17841\n",
      "loss: 1.9161932468414307, batch: 8901 out of 17841\n",
      "loss: 1.882103443145752, batch: 8951 out of 17841\n",
      "loss: 1.916770339012146, batch: 9001 out of 17841\n",
      "loss: 1.687840223312378, batch: 9051 out of 17841\n",
      "loss: 1.7463152408599854, batch: 9101 out of 17841\n",
      "loss: 1.8212008476257324, batch: 9151 out of 17841\n",
      "loss: 1.707449197769165, batch: 9201 out of 17841\n",
      "loss: 1.7294156551361084, batch: 9251 out of 17841\n",
      "loss: 1.8855576515197754, batch: 9301 out of 17841\n",
      "loss: 1.9173952341079712, batch: 9351 out of 17841\n",
      "loss: 1.773123860359192, batch: 9401 out of 17841\n",
      "loss: 1.7620609998703003, batch: 9451 out of 17841\n",
      "loss: 1.8062057495117188, batch: 9501 out of 17841\n",
      "loss: 1.713592529296875, batch: 9551 out of 17841\n",
      "loss: 1.832601547241211, batch: 9601 out of 17841\n",
      "loss: 1.8496466875076294, batch: 9651 out of 17841\n",
      "loss: 1.8361215591430664, batch: 9701 out of 17841\n",
      "loss: 1.8072285652160645, batch: 9751 out of 17841\n",
      "loss: 1.6734472513198853, batch: 9801 out of 17841\n",
      "loss: 1.897378921508789, batch: 9851 out of 17841\n",
      "loss: 1.7012348175048828, batch: 9901 out of 17841\n",
      "loss: 1.8530699014663696, batch: 9951 out of 17841\n",
      "loss: 1.78116774559021, batch: 10001 out of 17841\n",
      "loss: 1.9034078121185303, batch: 10051 out of 17841\n",
      "loss: 1.8160371780395508, batch: 10101 out of 17841\n",
      "loss: 1.806596040725708, batch: 10151 out of 17841\n",
      "loss: 1.9315427541732788, batch: 10201 out of 17841\n",
      "loss: 1.6929256916046143, batch: 10251 out of 17841\n",
      "loss: 1.7903083562850952, batch: 10301 out of 17841\n",
      "loss: 1.762437105178833, batch: 10351 out of 17841\n",
      "loss: 1.804265022277832, batch: 10401 out of 17841\n",
      "loss: 1.691147804260254, batch: 10451 out of 17841\n",
      "loss: 1.9067859649658203, batch: 10501 out of 17841\n",
      "loss: 1.883124828338623, batch: 10551 out of 17841\n",
      "loss: 1.8522071838378906, batch: 10601 out of 17841\n",
      "loss: 1.780737280845642, batch: 10651 out of 17841\n",
      "loss: 1.8371474742889404, batch: 10701 out of 17841\n",
      "loss: 1.9503097534179688, batch: 10751 out of 17841\n",
      "loss: 1.8391422033309937, batch: 10801 out of 17841\n",
      "loss: 1.7892731428146362, batch: 10851 out of 17841\n",
      "loss: 1.8078070878982544, batch: 10901 out of 17841\n",
      "loss: 1.7233715057373047, batch: 10951 out of 17841\n",
      "loss: 1.8824479579925537, batch: 11001 out of 17841\n",
      "loss: 1.8208591938018799, batch: 11051 out of 17841\n",
      "loss: 1.7123602628707886, batch: 11101 out of 17841\n",
      "loss: 1.950880765914917, batch: 11151 out of 17841\n",
      "loss: 1.7374308109283447, batch: 11201 out of 17841\n",
      "loss: 1.8069531917572021, batch: 11251 out of 17841\n",
      "loss: 1.784923791885376, batch: 11301 out of 17841\n",
      "loss: 1.8907032012939453, batch: 11351 out of 17841\n",
      "loss: 1.7125592231750488, batch: 11401 out of 17841\n",
      "loss: 1.8453961610794067, batch: 11451 out of 17841\n",
      "loss: 1.723393201828003, batch: 11501 out of 17841\n",
      "loss: 1.8480570316314697, batch: 11551 out of 17841\n",
      "loss: 1.7964167594909668, batch: 11601 out of 17841\n",
      "loss: 1.8611795902252197, batch: 11651 out of 17841\n",
      "loss: 1.8400499820709229, batch: 11701 out of 17841\n",
      "loss: 2.071528196334839, batch: 11751 out of 17841\n",
      "loss: 1.8249903917312622, batch: 11801 out of 17841\n",
      "loss: 1.6610488891601562, batch: 11851 out of 17841\n",
      "loss: 1.818026065826416, batch: 11901 out of 17841\n",
      "loss: 1.9101842641830444, batch: 11951 out of 17841\n",
      "loss: 1.9953663349151611, batch: 12001 out of 17841\n",
      "loss: 1.8101065158843994, batch: 12051 out of 17841\n",
      "loss: 1.760230302810669, batch: 12101 out of 17841\n",
      "loss: 1.7805417776107788, batch: 12151 out of 17841\n",
      "loss: 1.8536624908447266, batch: 12201 out of 17841\n",
      "loss: 1.7005040645599365, batch: 12251 out of 17841\n",
      "loss: 1.743722677230835, batch: 12301 out of 17841\n",
      "loss: 1.7721704244613647, batch: 12351 out of 17841\n",
      "loss: 1.7018219232559204, batch: 12401 out of 17841\n",
      "loss: 1.8654735088348389, batch: 12451 out of 17841\n",
      "loss: 1.845928430557251, batch: 12501 out of 17841\n",
      "loss: 1.9134976863861084, batch: 12551 out of 17841\n",
      "loss: 1.903609275817871, batch: 12601 out of 17841\n",
      "loss: 1.7834876775741577, batch: 12651 out of 17841\n",
      "loss: 1.9947935342788696, batch: 12701 out of 17841\n",
      "loss: 1.824904203414917, batch: 12751 out of 17841\n",
      "loss: 1.7683193683624268, batch: 12801 out of 17841\n",
      "loss: 1.7893729209899902, batch: 12851 out of 17841\n",
      "loss: 1.8594698905944824, batch: 12901 out of 17841\n",
      "loss: 1.8328020572662354, batch: 12951 out of 17841\n",
      "loss: 1.778583288192749, batch: 13001 out of 17841\n",
      "loss: 1.7859466075897217, batch: 13051 out of 17841\n",
      "loss: 1.7621148824691772, batch: 13101 out of 17841\n",
      "loss: 1.6849496364593506, batch: 13151 out of 17841\n",
      "loss: 1.8354904651641846, batch: 13201 out of 17841\n",
      "loss: 1.8273334503173828, batch: 13251 out of 17841\n",
      "loss: 1.92399263381958, batch: 13301 out of 17841\n",
      "loss: 1.8065757751464844, batch: 13351 out of 17841\n",
      "loss: 1.8246829509735107, batch: 13401 out of 17841\n",
      "loss: 1.805640697479248, batch: 13451 out of 17841\n",
      "loss: 1.7987217903137207, batch: 13501 out of 17841\n",
      "loss: 1.8372492790222168, batch: 13551 out of 17841\n",
      "loss: 1.8651189804077148, batch: 13601 out of 17841\n",
      "loss: 1.8887555599212646, batch: 13651 out of 17841\n",
      "loss: 1.680083990097046, batch: 13701 out of 17841\n",
      "loss: 1.698446273803711, batch: 13751 out of 17841\n",
      "loss: 1.7643799781799316, batch: 13801 out of 17841\n",
      "loss: 1.7324355840682983, batch: 13851 out of 17841\n",
      "loss: 1.6996644735336304, batch: 13901 out of 17841\n",
      "loss: 1.6704752445220947, batch: 13951 out of 17841\n",
      "loss: 1.7766375541687012, batch: 14001 out of 17841\n",
      "loss: 1.752610445022583, batch: 14051 out of 17841\n",
      "loss: 1.7934490442276, batch: 14101 out of 17841\n",
      "loss: 1.9833821058273315, batch: 14151 out of 17841\n",
      "loss: 1.8011435270309448, batch: 14201 out of 17841\n",
      "loss: 1.8387982845306396, batch: 14251 out of 17841\n",
      "loss: 1.7713426351547241, batch: 14301 out of 17841\n",
      "loss: 1.959035873413086, batch: 14351 out of 17841\n",
      "loss: 1.7108741998672485, batch: 14401 out of 17841\n",
      "loss: 1.8011553287506104, batch: 14451 out of 17841\n",
      "loss: 2.0284159183502197, batch: 14501 out of 17841\n",
      "loss: 1.827354907989502, batch: 14551 out of 17841\n",
      "loss: 1.843979835510254, batch: 14601 out of 17841\n",
      "loss: 1.922347068786621, batch: 14651 out of 17841\n",
      "loss: 1.7717845439910889, batch: 14701 out of 17841\n",
      "loss: 1.7112376689910889, batch: 14751 out of 17841\n",
      "loss: 1.6606724262237549, batch: 14801 out of 17841\n",
      "loss: 1.8506669998168945, batch: 14851 out of 17841\n",
      "loss: 1.7732784748077393, batch: 14901 out of 17841\n",
      "loss: 1.923319935798645, batch: 14951 out of 17841\n",
      "loss: 1.6041018962860107, batch: 15001 out of 17841\n",
      "loss: 1.9080069065093994, batch: 15051 out of 17841\n",
      "loss: 2.0321409702301025, batch: 15101 out of 17841\n",
      "loss: 1.8356080055236816, batch: 15151 out of 17841\n",
      "loss: 1.7930856943130493, batch: 15201 out of 17841\n",
      "loss: 1.662877082824707, batch: 15251 out of 17841\n",
      "loss: 1.7508189678192139, batch: 15301 out of 17841\n",
      "loss: 1.8055598735809326, batch: 15351 out of 17841\n",
      "loss: 1.9215837717056274, batch: 15401 out of 17841\n",
      "loss: 1.9509066343307495, batch: 15451 out of 17841\n",
      "loss: 1.7990317344665527, batch: 15501 out of 17841\n",
      "loss: 1.707216501235962, batch: 15551 out of 17841\n",
      "loss: 2.010133981704712, batch: 15601 out of 17841\n",
      "loss: 1.6585092544555664, batch: 15651 out of 17841\n",
      "loss: 1.8009570837020874, batch: 15701 out of 17841\n",
      "loss: 1.6682446002960205, batch: 15751 out of 17841\n",
      "loss: 1.7650511264801025, batch: 15801 out of 17841\n",
      "loss: 1.6668815612792969, batch: 15851 out of 17841\n",
      "loss: 1.6910606622695923, batch: 15901 out of 17841\n",
      "loss: 1.7479959726333618, batch: 15951 out of 17841\n",
      "loss: 1.9153869152069092, batch: 16001 out of 17841\n",
      "loss: 1.8076527118682861, batch: 16051 out of 17841\n",
      "loss: 1.7305421829223633, batch: 16101 out of 17841\n",
      "loss: 1.5952376127243042, batch: 16151 out of 17841\n",
      "loss: 1.8903415203094482, batch: 16201 out of 17841\n",
      "loss: 1.7607221603393555, batch: 16251 out of 17841\n",
      "loss: 1.69138503074646, batch: 16301 out of 17841\n",
      "loss: 1.775689959526062, batch: 16351 out of 17841\n",
      "loss: 1.8158299922943115, batch: 16401 out of 17841\n",
      "loss: 1.8073291778564453, batch: 16451 out of 17841\n",
      "loss: 1.8981596231460571, batch: 16501 out of 17841\n",
      "loss: 1.7470107078552246, batch: 16551 out of 17841\n",
      "loss: 1.8324096202850342, batch: 16601 out of 17841\n",
      "loss: 1.7794394493103027, batch: 16651 out of 17841\n",
      "loss: 1.9096647500991821, batch: 16701 out of 17841\n",
      "loss: 1.7380292415618896, batch: 16751 out of 17841\n",
      "loss: 1.7851004600524902, batch: 16801 out of 17841\n",
      "loss: 1.7799842357635498, batch: 16851 out of 17841\n",
      "loss: 1.807070016860962, batch: 16901 out of 17841\n",
      "loss: 1.7140229940414429, batch: 16951 out of 17841\n",
      "loss: 1.925805687904358, batch: 17001 out of 17841\n",
      "loss: 1.8395919799804688, batch: 17051 out of 17841\n",
      "loss: 1.7560977935791016, batch: 17101 out of 17841\n",
      "loss: 1.7080860137939453, batch: 17151 out of 17841\n",
      "loss: 1.7271430492401123, batch: 17201 out of 17841\n",
      "loss: 1.8028717041015625, batch: 17251 out of 17841\n",
      "loss: 1.7971700429916382, batch: 17301 out of 17841\n",
      "loss: 1.5789822340011597, batch: 17351 out of 17841\n",
      "loss: 1.8098857402801514, batch: 17401 out of 17841\n",
      "loss: 1.8851897716522217, batch: 17451 out of 17841\n",
      "loss: 1.850602626800537, batch: 17501 out of 17841\n",
      "loss: 1.7323451042175293, batch: 17551 out of 17841\n",
      "loss: 1.8190011978149414, batch: 17601 out of 17841\n",
      "loss: 1.8626196384429932, batch: 17651 out of 17841\n",
      "loss: 1.7270503044128418, batch: 17701 out of 17841\n",
      "loss: 1.8174002170562744, batch: 17751 out of 17841\n",
      "loss: 1.846396803855896, batch: 17801 out of 17841\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.7242658138275146, batch: 1 out of 17841\n",
      "loss: 1.8488491773605347, batch: 51 out of 17841\n",
      "loss: 1.8023942708969116, batch: 101 out of 17841\n",
      "loss: 1.7184765338897705, batch: 151 out of 17841\n",
      "loss: 1.7628099918365479, batch: 201 out of 17841\n",
      "loss: 1.8213460445404053, batch: 251 out of 17841\n",
      "loss: 1.7865557670593262, batch: 301 out of 17841\n",
      "loss: 1.8733940124511719, batch: 351 out of 17841\n",
      "loss: 1.903625249862671, batch: 401 out of 17841\n",
      "loss: 1.751946210861206, batch: 451 out of 17841\n",
      "loss: 1.9692209959030151, batch: 501 out of 17841\n",
      "loss: 1.7220735549926758, batch: 551 out of 17841\n",
      "loss: 1.856222152709961, batch: 601 out of 17841\n",
      "loss: 1.8460898399353027, batch: 651 out of 17841\n",
      "loss: 1.7911168336868286, batch: 701 out of 17841\n",
      "loss: 1.8447766304016113, batch: 751 out of 17841\n",
      "loss: 1.880007266998291, batch: 801 out of 17841\n",
      "loss: 1.7596828937530518, batch: 851 out of 17841\n",
      "loss: 1.728278636932373, batch: 901 out of 17841\n",
      "loss: 1.8967489004135132, batch: 951 out of 17841\n",
      "loss: 1.8020265102386475, batch: 1001 out of 17841\n",
      "loss: 1.5752618312835693, batch: 1051 out of 17841\n",
      "loss: 1.9831552505493164, batch: 1101 out of 17841\n",
      "loss: 1.7558026313781738, batch: 1151 out of 17841\n",
      "loss: 1.8697991371154785, batch: 1201 out of 17841\n",
      "loss: 1.7168526649475098, batch: 1251 out of 17841\n",
      "loss: 1.6831755638122559, batch: 1301 out of 17841\n",
      "loss: 1.7340233325958252, batch: 1351 out of 17841\n",
      "loss: 1.7526302337646484, batch: 1401 out of 17841\n",
      "loss: 1.7135440111160278, batch: 1451 out of 17841\n",
      "loss: 1.8069852590560913, batch: 1501 out of 17841\n",
      "loss: 1.6860482692718506, batch: 1551 out of 17841\n",
      "loss: 1.880045771598816, batch: 1601 out of 17841\n",
      "loss: 1.7632670402526855, batch: 1651 out of 17841\n",
      "loss: 1.622989535331726, batch: 1701 out of 17841\n",
      "loss: 1.7039456367492676, batch: 1751 out of 17841\n",
      "loss: 1.8916831016540527, batch: 1801 out of 17841\n",
      "loss: 1.9690086841583252, batch: 1851 out of 17841\n",
      "loss: 1.8379688262939453, batch: 1901 out of 17841\n",
      "loss: 1.838861107826233, batch: 1951 out of 17841\n",
      "loss: 1.8672583103179932, batch: 2001 out of 17841\n",
      "loss: 1.7828447818756104, batch: 2051 out of 17841\n",
      "loss: 1.862100601196289, batch: 2101 out of 17841\n",
      "loss: 1.9167231321334839, batch: 2151 out of 17841\n",
      "loss: 1.8626461029052734, batch: 2201 out of 17841\n",
      "loss: 1.7449501752853394, batch: 2251 out of 17841\n",
      "loss: 1.735926866531372, batch: 2301 out of 17841\n",
      "loss: 1.7784839868545532, batch: 2351 out of 17841\n",
      "loss: 1.9657655954360962, batch: 2401 out of 17841\n",
      "loss: 1.8425593376159668, batch: 2451 out of 17841\n",
      "loss: 1.7621707916259766, batch: 2501 out of 17841\n",
      "loss: 1.8068420886993408, batch: 2551 out of 17841\n",
      "loss: 1.6677265167236328, batch: 2601 out of 17841\n",
      "loss: 1.885456919670105, batch: 2651 out of 17841\n",
      "loss: 1.6933033466339111, batch: 2701 out of 17841\n",
      "loss: 1.8807507753372192, batch: 2751 out of 17841\n",
      "loss: 1.8207223415374756, batch: 2801 out of 17841\n",
      "loss: 1.7028627395629883, batch: 2851 out of 17841\n",
      "loss: 1.6968947649002075, batch: 2901 out of 17841\n",
      "loss: 1.811521291732788, batch: 2951 out of 17841\n",
      "loss: 1.656163215637207, batch: 3001 out of 17841\n",
      "loss: 1.8889470100402832, batch: 3051 out of 17841\n",
      "loss: 1.9894189834594727, batch: 3101 out of 17841\n",
      "loss: 1.8303297758102417, batch: 3151 out of 17841\n",
      "loss: 1.8753849267959595, batch: 3201 out of 17841\n",
      "loss: 1.8997068405151367, batch: 3251 out of 17841\n",
      "loss: 1.8063578605651855, batch: 3301 out of 17841\n",
      "loss: 1.8347411155700684, batch: 3351 out of 17841\n",
      "loss: 1.8179811239242554, batch: 3401 out of 17841\n",
      "loss: 1.8012715578079224, batch: 3451 out of 17841\n",
      "loss: 1.687408208847046, batch: 3501 out of 17841\n",
      "loss: 1.839112639427185, batch: 3551 out of 17841\n",
      "loss: 1.833856225013733, batch: 3601 out of 17841\n",
      "loss: 1.8423824310302734, batch: 3651 out of 17841\n",
      "loss: 1.7812138795852661, batch: 3701 out of 17841\n",
      "loss: 1.7982221841812134, batch: 3751 out of 17841\n",
      "loss: 1.7972097396850586, batch: 3801 out of 17841\n",
      "loss: 1.9521605968475342, batch: 3851 out of 17841\n",
      "loss: 1.8223164081573486, batch: 3901 out of 17841\n",
      "loss: 1.7199797630310059, batch: 3951 out of 17841\n",
      "loss: 1.7159106731414795, batch: 4001 out of 17841\n",
      "loss: 1.7231391668319702, batch: 4051 out of 17841\n",
      "loss: 1.6979575157165527, batch: 4101 out of 17841\n",
      "loss: 1.7880054712295532, batch: 4151 out of 17841\n",
      "loss: 1.7328789234161377, batch: 4201 out of 17841\n",
      "loss: 1.7281911373138428, batch: 4251 out of 17841\n",
      "loss: 1.7191720008850098, batch: 4301 out of 17841\n",
      "loss: 1.8244719505310059, batch: 4351 out of 17841\n",
      "loss: 1.8378959894180298, batch: 4401 out of 17841\n",
      "loss: 1.8087519407272339, batch: 4451 out of 17841\n",
      "loss: 1.6035797595977783, batch: 4501 out of 17841\n",
      "loss: 1.8964498043060303, batch: 4551 out of 17841\n",
      "loss: 1.6989834308624268, batch: 4601 out of 17841\n",
      "loss: 1.763700246810913, batch: 4651 out of 17841\n",
      "loss: 1.9002888202667236, batch: 4701 out of 17841\n",
      "loss: 1.7216897010803223, batch: 4751 out of 17841\n",
      "loss: 1.6800248622894287, batch: 4801 out of 17841\n",
      "loss: 1.7194445133209229, batch: 4851 out of 17841\n",
      "loss: 1.9271843433380127, batch: 4901 out of 17841\n",
      "loss: 1.809244990348816, batch: 4951 out of 17841\n",
      "loss: 1.797936201095581, batch: 5001 out of 17841\n",
      "loss: 1.7643088102340698, batch: 5051 out of 17841\n",
      "loss: 1.867803692817688, batch: 5101 out of 17841\n",
      "loss: 1.9513288736343384, batch: 5151 out of 17841\n",
      "loss: 1.762953758239746, batch: 5201 out of 17841\n",
      "loss: 1.7634514570236206, batch: 5251 out of 17841\n",
      "loss: 1.7001616954803467, batch: 5301 out of 17841\n",
      "loss: 1.8406000137329102, batch: 5351 out of 17841\n",
      "loss: 1.9456721544265747, batch: 5401 out of 17841\n",
      "loss: 1.8555011749267578, batch: 5451 out of 17841\n",
      "loss: 1.8084036111831665, batch: 5501 out of 17841\n",
      "loss: 1.712755560874939, batch: 5551 out of 17841\n",
      "loss: 1.902155876159668, batch: 5601 out of 17841\n",
      "loss: 1.7523622512817383, batch: 5651 out of 17841\n",
      "loss: 1.705433964729309, batch: 5701 out of 17841\n",
      "loss: 1.8355990648269653, batch: 5751 out of 17841\n",
      "loss: 1.6915109157562256, batch: 5801 out of 17841\n",
      "loss: 1.95064115524292, batch: 5851 out of 17841\n",
      "loss: 1.8347299098968506, batch: 5901 out of 17841\n",
      "loss: 1.690992832183838, batch: 5951 out of 17841\n",
      "loss: 1.8616664409637451, batch: 6001 out of 17841\n",
      "loss: 1.9640017747879028, batch: 6051 out of 17841\n",
      "loss: 1.8054784536361694, batch: 6101 out of 17841\n",
      "loss: 1.7259483337402344, batch: 6151 out of 17841\n",
      "loss: 1.808542251586914, batch: 6201 out of 17841\n",
      "loss: 1.7986153364181519, batch: 6251 out of 17841\n",
      "loss: 1.7668654918670654, batch: 6301 out of 17841\n",
      "loss: 1.928053379058838, batch: 6351 out of 17841\n",
      "loss: 1.792009711265564, batch: 6401 out of 17841\n",
      "loss: 1.785797119140625, batch: 6451 out of 17841\n",
      "loss: 1.7864794731140137, batch: 6501 out of 17841\n",
      "loss: 1.7000141143798828, batch: 6551 out of 17841\n",
      "loss: 1.7526750564575195, batch: 6601 out of 17841\n",
      "loss: 1.8583488464355469, batch: 6651 out of 17841\n",
      "loss: 1.7879347801208496, batch: 6701 out of 17841\n",
      "loss: 1.8959908485412598, batch: 6751 out of 17841\n",
      "loss: 1.7903928756713867, batch: 6801 out of 17841\n",
      "loss: 1.9113047122955322, batch: 6851 out of 17841\n",
      "loss: 1.8369717597961426, batch: 6901 out of 17841\n",
      "loss: 1.8300933837890625, batch: 6951 out of 17841\n",
      "loss: 1.861849308013916, batch: 7001 out of 17841\n",
      "loss: 1.7799742221832275, batch: 7051 out of 17841\n",
      "loss: 1.8721517324447632, batch: 7101 out of 17841\n",
      "loss: 1.8104958534240723, batch: 7151 out of 17841\n",
      "loss: 1.7615118026733398, batch: 7201 out of 17841\n",
      "loss: 1.8552359342575073, batch: 7251 out of 17841\n",
      "loss: 1.6842318773269653, batch: 7301 out of 17841\n",
      "loss: 1.6833540201187134, batch: 7351 out of 17841\n",
      "loss: 1.7663922309875488, batch: 7401 out of 17841\n",
      "loss: 1.807432770729065, batch: 7451 out of 17841\n",
      "loss: 1.724162220954895, batch: 7501 out of 17841\n",
      "loss: 1.7341245412826538, batch: 7551 out of 17841\n",
      "loss: 1.8746724128723145, batch: 7601 out of 17841\n",
      "loss: 1.7799177169799805, batch: 7651 out of 17841\n",
      "loss: 1.8073468208312988, batch: 7701 out of 17841\n",
      "loss: 1.8207554817199707, batch: 7751 out of 17841\n",
      "loss: 1.8344814777374268, batch: 7801 out of 17841\n",
      "loss: 1.8777945041656494, batch: 7851 out of 17841\n",
      "loss: 1.7676935195922852, batch: 7901 out of 17841\n",
      "loss: 1.8373146057128906, batch: 7951 out of 17841\n",
      "loss: 1.8902312517166138, batch: 8001 out of 17841\n",
      "loss: 1.7763727903366089, batch: 8051 out of 17841\n",
      "loss: 1.7248451709747314, batch: 8101 out of 17841\n",
      "loss: 1.6792742013931274, batch: 8151 out of 17841\n",
      "loss: 1.830153465270996, batch: 8201 out of 17841\n",
      "loss: 1.9129014015197754, batch: 8251 out of 17841\n",
      "loss: 1.6610338687896729, batch: 8301 out of 17841\n",
      "loss: 1.7270156145095825, batch: 8351 out of 17841\n",
      "loss: 1.9281761646270752, batch: 8401 out of 17841\n",
      "loss: 1.8418424129486084, batch: 8451 out of 17841\n",
      "loss: 1.7806934118270874, batch: 8501 out of 17841\n",
      "loss: 1.8185155391693115, batch: 8551 out of 17841\n",
      "loss: 1.7510313987731934, batch: 8601 out of 17841\n",
      "loss: 1.922917127609253, batch: 8651 out of 17841\n",
      "loss: 1.584256649017334, batch: 8701 out of 17841\n",
      "loss: 1.888632893562317, batch: 8751 out of 17841\n",
      "loss: 1.7767072916030884, batch: 8801 out of 17841\n",
      "loss: 1.6444382667541504, batch: 8851 out of 17841\n",
      "loss: 1.8274109363555908, batch: 8901 out of 17841\n",
      "loss: 1.8373498916625977, batch: 8951 out of 17841\n",
      "loss: 1.7742305994033813, batch: 9001 out of 17841\n",
      "loss: 1.819281816482544, batch: 9051 out of 17841\n",
      "loss: 1.784623146057129, batch: 9101 out of 17841\n",
      "loss: 1.698242425918579, batch: 9151 out of 17841\n",
      "loss: 1.7709559202194214, batch: 9201 out of 17841\n",
      "loss: 1.8323887586593628, batch: 9251 out of 17841\n",
      "loss: 1.88239586353302, batch: 9301 out of 17841\n",
      "loss: 1.9128402471542358, batch: 9351 out of 17841\n",
      "loss: 1.7760906219482422, batch: 9401 out of 17841\n",
      "loss: 1.8053113222122192, batch: 9451 out of 17841\n",
      "loss: 1.9119205474853516, batch: 9501 out of 17841\n",
      "loss: 1.9154438972473145, batch: 9551 out of 17841\n",
      "loss: 1.790898084640503, batch: 9601 out of 17841\n",
      "loss: 1.7849476337432861, batch: 9651 out of 17841\n",
      "loss: 1.8232204914093018, batch: 9701 out of 17841\n",
      "loss: 1.696364164352417, batch: 9751 out of 17841\n",
      "loss: 1.7967556715011597, batch: 9801 out of 17841\n",
      "loss: 1.7993836402893066, batch: 9851 out of 17841\n",
      "loss: 1.5316250324249268, batch: 9901 out of 17841\n",
      "loss: 1.7898285388946533, batch: 9951 out of 17841\n",
      "loss: 1.872231125831604, batch: 10001 out of 17841\n",
      "loss: 1.8624975681304932, batch: 10051 out of 17841\n",
      "loss: 1.8806873559951782, batch: 10101 out of 17841\n",
      "loss: 1.8370931148529053, batch: 10151 out of 17841\n",
      "loss: 1.828018307685852, batch: 10201 out of 17841\n",
      "loss: 1.7924549579620361, batch: 10251 out of 17841\n",
      "loss: 1.7432340383529663, batch: 10301 out of 17841\n",
      "loss: 1.8208056688308716, batch: 10351 out of 17841\n",
      "loss: 1.8432024717330933, batch: 10401 out of 17841\n",
      "loss: 1.8474998474121094, batch: 10451 out of 17841\n",
      "loss: 1.7563831806182861, batch: 10501 out of 17841\n",
      "loss: 1.806898593902588, batch: 10551 out of 17841\n",
      "loss: 1.7234084606170654, batch: 10601 out of 17841\n",
      "loss: 1.8744244575500488, batch: 10651 out of 17841\n",
      "loss: 1.7372848987579346, batch: 10701 out of 17841\n",
      "loss: 1.7482733726501465, batch: 10751 out of 17841\n",
      "loss: 1.8210244178771973, batch: 10801 out of 17841\n",
      "loss: 1.751023292541504, batch: 10851 out of 17841\n",
      "loss: 1.8429938554763794, batch: 10901 out of 17841\n",
      "loss: 1.7910561561584473, batch: 10951 out of 17841\n",
      "loss: 1.8233304023742676, batch: 11001 out of 17841\n",
      "loss: 1.7750756740570068, batch: 11051 out of 17841\n",
      "loss: 1.7954602241516113, batch: 11101 out of 17841\n",
      "loss: 1.7012670040130615, batch: 11151 out of 17841\n",
      "loss: 1.7771838903427124, batch: 11201 out of 17841\n",
      "loss: 1.8117185831069946, batch: 11251 out of 17841\n",
      "loss: 1.744393229484558, batch: 11301 out of 17841\n",
      "loss: 1.8404595851898193, batch: 11351 out of 17841\n",
      "loss: 1.8271892070770264, batch: 11401 out of 17841\n",
      "loss: 1.8703073263168335, batch: 11451 out of 17841\n",
      "loss: 1.6639007329940796, batch: 11501 out of 17841\n",
      "loss: 1.8262183666229248, batch: 11551 out of 17841\n",
      "loss: 1.9947917461395264, batch: 11601 out of 17841\n",
      "loss: 1.741521954536438, batch: 11651 out of 17841\n",
      "loss: 1.778550624847412, batch: 11701 out of 17841\n",
      "loss: 2.0031027793884277, batch: 11751 out of 17841\n",
      "loss: 1.9053163528442383, batch: 11801 out of 17841\n",
      "loss: 1.7973928451538086, batch: 11851 out of 17841\n",
      "loss: 1.7821811437606812, batch: 11901 out of 17841\n",
      "loss: 1.7568116188049316, batch: 11951 out of 17841\n",
      "loss: 1.8032617568969727, batch: 12001 out of 17841\n",
      "loss: 1.7702497243881226, batch: 12051 out of 17841\n",
      "loss: 1.904578447341919, batch: 12101 out of 17841\n",
      "loss: 1.7435411214828491, batch: 12151 out of 17841\n",
      "loss: 1.7763910293579102, batch: 12201 out of 17841\n",
      "loss: 1.8676328659057617, batch: 12251 out of 17841\n",
      "loss: 1.8859705924987793, batch: 12301 out of 17841\n",
      "loss: 1.80902898311615, batch: 12351 out of 17841\n",
      "loss: 1.7792222499847412, batch: 12401 out of 17841\n",
      "loss: 1.7555934190750122, batch: 12451 out of 17841\n",
      "loss: 1.6393003463745117, batch: 12501 out of 17841\n",
      "loss: 1.7930281162261963, batch: 12551 out of 17841\n",
      "loss: 1.7521648406982422, batch: 12601 out of 17841\n",
      "loss: 1.7401121854782104, batch: 12651 out of 17841\n",
      "loss: 1.7848403453826904, batch: 12701 out of 17841\n",
      "loss: 1.9017131328582764, batch: 12751 out of 17841\n",
      "loss: 1.72063148021698, batch: 12801 out of 17841\n",
      "loss: 1.7921332120895386, batch: 12851 out of 17841\n",
      "loss: 1.6581671237945557, batch: 12901 out of 17841\n",
      "loss: 1.828726053237915, batch: 12951 out of 17841\n",
      "loss: 1.8072357177734375, batch: 13001 out of 17841\n",
      "loss: 1.7845003604888916, batch: 13051 out of 17841\n",
      "loss: 1.7886841297149658, batch: 13101 out of 17841\n",
      "loss: 1.5832395553588867, batch: 13151 out of 17841\n",
      "loss: 1.6654422283172607, batch: 13201 out of 17841\n",
      "loss: 1.8224232196807861, batch: 13251 out of 17841\n",
      "loss: 1.7407410144805908, batch: 13301 out of 17841\n",
      "loss: 1.7506604194641113, batch: 13351 out of 17841\n",
      "loss: 1.9420890808105469, batch: 13401 out of 17841\n",
      "loss: 1.8212611675262451, batch: 13451 out of 17841\n",
      "loss: 1.7762131690979004, batch: 13501 out of 17841\n",
      "loss: 1.7952059507369995, batch: 13551 out of 17841\n",
      "loss: 1.903231143951416, batch: 13601 out of 17841\n",
      "loss: 1.8825310468673706, batch: 13651 out of 17841\n",
      "loss: 1.8340452909469604, batch: 13701 out of 17841\n",
      "loss: 1.8370531797409058, batch: 13751 out of 17841\n",
      "loss: 1.7881978750228882, batch: 13801 out of 17841\n",
      "loss: 1.7386136054992676, batch: 13851 out of 17841\n",
      "loss: 1.8514869213104248, batch: 13901 out of 17841\n",
      "loss: 1.9189502000808716, batch: 13951 out of 17841\n",
      "loss: 1.778259515762329, batch: 14001 out of 17841\n",
      "loss: 1.7439243793487549, batch: 14051 out of 17841\n",
      "loss: 1.8122332096099854, batch: 14101 out of 17841\n",
      "loss: 1.9286386966705322, batch: 14151 out of 17841\n",
      "loss: 1.883533000946045, batch: 14201 out of 17841\n",
      "loss: 1.8030773401260376, batch: 14251 out of 17841\n",
      "loss: 1.8346188068389893, batch: 14301 out of 17841\n",
      "loss: 1.8409072160720825, batch: 14351 out of 17841\n",
      "loss: 1.838388442993164, batch: 14401 out of 17841\n",
      "loss: 1.8586485385894775, batch: 14451 out of 17841\n",
      "loss: 1.7601078748703003, batch: 14501 out of 17841\n",
      "loss: 1.8532958030700684, batch: 14551 out of 17841\n",
      "loss: 1.8486922979354858, batch: 14601 out of 17841\n",
      "loss: 1.707939863204956, batch: 14651 out of 17841\n",
      "loss: 1.7605781555175781, batch: 14701 out of 17841\n",
      "loss: 1.8028939962387085, batch: 14751 out of 17841\n",
      "loss: 1.6665558815002441, batch: 14801 out of 17841\n",
      "loss: 1.8097281455993652, batch: 14851 out of 17841\n",
      "loss: 1.7228349447250366, batch: 14901 out of 17841\n",
      "loss: 1.8131539821624756, batch: 14951 out of 17841\n",
      "loss: 1.7803257703781128, batch: 15001 out of 17841\n",
      "loss: 1.816301941871643, batch: 15051 out of 17841\n",
      "loss: 1.6764814853668213, batch: 15101 out of 17841\n",
      "loss: 1.7395927906036377, batch: 15151 out of 17841\n",
      "loss: 1.7765700817108154, batch: 15201 out of 17841\n",
      "loss: 1.78127121925354, batch: 15251 out of 17841\n",
      "loss: 1.8644968271255493, batch: 15301 out of 17841\n",
      "loss: 1.8037561178207397, batch: 15351 out of 17841\n",
      "loss: 1.899214267730713, batch: 15401 out of 17841\n",
      "loss: 1.9098050594329834, batch: 15451 out of 17841\n",
      "loss: 1.7916029691696167, batch: 15501 out of 17841\n",
      "loss: 1.8786228895187378, batch: 15551 out of 17841\n",
      "loss: 1.7438404560089111, batch: 15601 out of 17841\n",
      "loss: 1.710241436958313, batch: 15651 out of 17841\n",
      "loss: 1.8278270959854126, batch: 15701 out of 17841\n",
      "loss: 1.65022611618042, batch: 15751 out of 17841\n",
      "loss: 1.8202159404754639, batch: 15801 out of 17841\n",
      "loss: 1.8710641860961914, batch: 15851 out of 17841\n",
      "loss: 1.9797277450561523, batch: 15901 out of 17841\n",
      "loss: 1.8288058042526245, batch: 15951 out of 17841\n",
      "loss: 1.686819076538086, batch: 16001 out of 17841\n",
      "loss: 1.7584888935089111, batch: 16051 out of 17841\n",
      "loss: 1.8726922273635864, batch: 16101 out of 17841\n",
      "loss: 1.826082706451416, batch: 16151 out of 17841\n",
      "loss: 1.828197717666626, batch: 16201 out of 17841\n",
      "loss: 1.733825922012329, batch: 16251 out of 17841\n",
      "loss: 1.77400541305542, batch: 16301 out of 17841\n",
      "loss: 1.8345017433166504, batch: 16351 out of 17841\n",
      "loss: 1.7682287693023682, batch: 16401 out of 17841\n",
      "loss: 1.7271329164505005, batch: 16451 out of 17841\n",
      "loss: 1.8479599952697754, batch: 16501 out of 17841\n",
      "loss: 1.9615193605422974, batch: 16551 out of 17841\n",
      "loss: 1.7978050708770752, batch: 16601 out of 17841\n",
      "loss: 1.7004395723342896, batch: 16651 out of 17841\n",
      "loss: 1.856477975845337, batch: 16701 out of 17841\n",
      "loss: 1.9472765922546387, batch: 16751 out of 17841\n",
      "loss: 1.7676641941070557, batch: 16801 out of 17841\n",
      "loss: 1.785498857498169, batch: 16851 out of 17841\n",
      "loss: 1.9008407592773438, batch: 16901 out of 17841\n",
      "loss: 1.9050989151000977, batch: 16951 out of 17841\n",
      "loss: 1.8680906295776367, batch: 17001 out of 17841\n",
      "loss: 1.8162717819213867, batch: 17051 out of 17841\n",
      "loss: 1.7771073579788208, batch: 17101 out of 17841\n",
      "loss: 1.7099394798278809, batch: 17151 out of 17841\n",
      "loss: 1.812941551208496, batch: 17201 out of 17841\n",
      "loss: 1.8580515384674072, batch: 17251 out of 17841\n",
      "loss: 1.7999279499053955, batch: 17301 out of 17841\n",
      "loss: 1.8100059032440186, batch: 17351 out of 17841\n",
      "loss: 1.73862886428833, batch: 17401 out of 17841\n",
      "loss: 1.788987159729004, batch: 17451 out of 17841\n",
      "loss: 1.7537899017333984, batch: 17501 out of 17841\n",
      "loss: 1.8423786163330078, batch: 17551 out of 17841\n",
      "loss: 1.8678909540176392, batch: 17601 out of 17841\n",
      "loss: 1.734917402267456, batch: 17651 out of 17841\n",
      "loss: 1.8543951511383057, batch: 17701 out of 17841\n",
      "loss: 1.8779425621032715, batch: 17751 out of 17841\n",
      "loss: 1.835867166519165, batch: 17801 out of 17841\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.7773776054382324, batch: 1 out of 17841\n",
      "loss: 1.8768365383148193, batch: 51 out of 17841\n",
      "loss: 1.7662947177886963, batch: 101 out of 17841\n",
      "loss: 1.81730318069458, batch: 151 out of 17841\n",
      "loss: 1.7586555480957031, batch: 201 out of 17841\n",
      "loss: 1.8380906581878662, batch: 251 out of 17841\n",
      "loss: 1.641831398010254, batch: 301 out of 17841\n",
      "loss: 1.6879569292068481, batch: 351 out of 17841\n",
      "loss: 1.860838770866394, batch: 401 out of 17841\n",
      "loss: 1.7774155139923096, batch: 451 out of 17841\n",
      "loss: 1.8853566646575928, batch: 501 out of 17841\n",
      "loss: 1.790474772453308, batch: 551 out of 17841\n",
      "loss: 1.827807903289795, batch: 601 out of 17841\n",
      "loss: 1.882434606552124, batch: 651 out of 17841\n",
      "loss: 1.6320593357086182, batch: 701 out of 17841\n",
      "loss: 1.78202223777771, batch: 751 out of 17841\n",
      "loss: 1.7537513971328735, batch: 801 out of 17841\n",
      "loss: 1.7164101600646973, batch: 851 out of 17841\n",
      "loss: 1.7779744863510132, batch: 901 out of 17841\n",
      "loss: 1.793670654296875, batch: 951 out of 17841\n",
      "loss: 1.8695402145385742, batch: 1001 out of 17841\n",
      "loss: 1.7072880268096924, batch: 1051 out of 17841\n",
      "loss: 1.7835161685943604, batch: 1101 out of 17841\n",
      "loss: 1.8359363079071045, batch: 1151 out of 17841\n",
      "loss: 1.8139559030532837, batch: 1201 out of 17841\n",
      "loss: 1.9427659511566162, batch: 1251 out of 17841\n",
      "loss: 1.7097240686416626, batch: 1301 out of 17841\n",
      "loss: 1.8526796102523804, batch: 1351 out of 17841\n",
      "loss: 1.7774338722229004, batch: 1401 out of 17841\n",
      "loss: 1.7471859455108643, batch: 1451 out of 17841\n",
      "loss: 1.788522481918335, batch: 1501 out of 17841\n",
      "loss: 1.9190672636032104, batch: 1551 out of 17841\n",
      "loss: 1.8715195655822754, batch: 1601 out of 17841\n",
      "loss: 1.8390148878097534, batch: 1651 out of 17841\n",
      "loss: 1.7801833152770996, batch: 1701 out of 17841\n",
      "loss: 1.839637041091919, batch: 1751 out of 17841\n",
      "loss: 1.8082375526428223, batch: 1801 out of 17841\n",
      "loss: 1.688194751739502, batch: 1851 out of 17841\n",
      "loss: 1.6829365491867065, batch: 1901 out of 17841\n",
      "loss: 1.7706305980682373, batch: 1951 out of 17841\n",
      "loss: 1.7096483707427979, batch: 2001 out of 17841\n",
      "loss: 1.7729902267456055, batch: 2051 out of 17841\n",
      "loss: 1.8279471397399902, batch: 2101 out of 17841\n",
      "loss: 1.7743864059448242, batch: 2151 out of 17841\n",
      "loss: 1.7426345348358154, batch: 2201 out of 17841\n",
      "loss: 1.7990168333053589, batch: 2251 out of 17841\n",
      "loss: 1.7913490533828735, batch: 2301 out of 17841\n",
      "loss: 1.829176664352417, batch: 2351 out of 17841\n",
      "loss: 1.774662733078003, batch: 2401 out of 17841\n",
      "loss: 1.774312138557434, batch: 2451 out of 17841\n",
      "loss: 1.7717630863189697, batch: 2501 out of 17841\n",
      "loss: 1.8233938217163086, batch: 2551 out of 17841\n",
      "loss: 1.7460161447525024, batch: 2601 out of 17841\n",
      "loss: 1.8136417865753174, batch: 2651 out of 17841\n",
      "loss: 1.6897239685058594, batch: 2701 out of 17841\n",
      "loss: 1.793804407119751, batch: 2751 out of 17841\n",
      "loss: 1.8778975009918213, batch: 2801 out of 17841\n",
      "loss: 1.7549335956573486, batch: 2851 out of 17841\n",
      "loss: 1.7579834461212158, batch: 2901 out of 17841\n",
      "loss: 1.8069387674331665, batch: 2951 out of 17841\n",
      "loss: 1.802721619606018, batch: 3001 out of 17841\n",
      "loss: 1.932422161102295, batch: 3051 out of 17841\n",
      "loss: 1.8837276697158813, batch: 3101 out of 17841\n",
      "loss: 1.7126233577728271, batch: 3151 out of 17841\n",
      "loss: 1.9177875518798828, batch: 3201 out of 17841\n",
      "loss: 1.685903549194336, batch: 3251 out of 17841\n",
      "loss: 2.007603406906128, batch: 3301 out of 17841\n",
      "loss: 1.807997465133667, batch: 3351 out of 17841\n",
      "loss: 1.8211276531219482, batch: 3401 out of 17841\n",
      "loss: 1.9220585823059082, batch: 3451 out of 17841\n",
      "loss: 1.6621840000152588, batch: 3501 out of 17841\n",
      "loss: 1.765750527381897, batch: 3551 out of 17841\n",
      "loss: 1.7675598859786987, batch: 3601 out of 17841\n",
      "loss: 1.6954755783081055, batch: 3651 out of 17841\n",
      "loss: 1.8091143369674683, batch: 3701 out of 17841\n",
      "loss: 1.8086538314819336, batch: 3751 out of 17841\n",
      "loss: 1.6764376163482666, batch: 3801 out of 17841\n",
      "loss: 1.8441276550292969, batch: 3851 out of 17841\n",
      "loss: 1.7742822170257568, batch: 3901 out of 17841\n",
      "loss: 1.7345466613769531, batch: 3951 out of 17841\n",
      "loss: 1.8419454097747803, batch: 4001 out of 17841\n",
      "loss: 1.7729039192199707, batch: 4051 out of 17841\n",
      "loss: 1.6855707168579102, batch: 4101 out of 17841\n",
      "loss: 1.866894006729126, batch: 4151 out of 17841\n",
      "loss: 1.8187124729156494, batch: 4201 out of 17841\n",
      "loss: 1.7609254121780396, batch: 4251 out of 17841\n",
      "loss: 1.8800909519195557, batch: 4301 out of 17841\n",
      "loss: 1.814319133758545, batch: 4351 out of 17841\n",
      "loss: 1.7263422012329102, batch: 4401 out of 17841\n",
      "loss: 1.7555856704711914, batch: 4451 out of 17841\n",
      "loss: 1.7747162580490112, batch: 4501 out of 17841\n",
      "loss: 1.7926795482635498, batch: 4551 out of 17841\n",
      "loss: 1.7990391254425049, batch: 4601 out of 17841\n",
      "loss: 1.9459707736968994, batch: 4651 out of 17841\n",
      "loss: 1.7842118740081787, batch: 4701 out of 17841\n",
      "loss: 1.7609074115753174, batch: 4751 out of 17841\n",
      "loss: 1.775282621383667, batch: 4801 out of 17841\n",
      "loss: 1.6577609777450562, batch: 4851 out of 17841\n",
      "loss: 1.7873826026916504, batch: 4901 out of 17841\n",
      "loss: 1.6991572380065918, batch: 4951 out of 17841\n",
      "loss: 1.8049373626708984, batch: 5001 out of 17841\n",
      "loss: 1.6559960842132568, batch: 5051 out of 17841\n",
      "loss: 1.8837116956710815, batch: 5101 out of 17841\n",
      "loss: 1.8849897384643555, batch: 5151 out of 17841\n",
      "loss: 1.8399853706359863, batch: 5201 out of 17841\n",
      "loss: 1.809631586074829, batch: 5251 out of 17841\n",
      "loss: 1.7479329109191895, batch: 5301 out of 17841\n",
      "loss: 1.8075881004333496, batch: 5351 out of 17841\n",
      "loss: 1.8983567953109741, batch: 5401 out of 17841\n",
      "loss: 1.7170379161834717, batch: 5451 out of 17841\n",
      "loss: 1.745974063873291, batch: 5501 out of 17841\n",
      "loss: 1.704964518547058, batch: 5551 out of 17841\n",
      "loss: 1.8169300556182861, batch: 5601 out of 17841\n",
      "loss: 1.918351650238037, batch: 5651 out of 17841\n",
      "loss: 1.8071904182434082, batch: 5701 out of 17841\n",
      "loss: 1.9033540487289429, batch: 5751 out of 17841\n",
      "loss: 1.797792673110962, batch: 5801 out of 17841\n",
      "loss: 1.898641586303711, batch: 5851 out of 17841\n",
      "loss: 1.8037726879119873, batch: 5901 out of 17841\n",
      "loss: 1.7616729736328125, batch: 5951 out of 17841\n",
      "loss: 1.8428159952163696, batch: 6001 out of 17841\n",
      "loss: 1.8605453968048096, batch: 6051 out of 17841\n",
      "loss: 1.7574307918548584, batch: 6101 out of 17841\n",
      "loss: 1.775770902633667, batch: 6151 out of 17841\n",
      "loss: 1.8492848873138428, batch: 6201 out of 17841\n",
      "loss: 1.7146506309509277, batch: 6251 out of 17841\n",
      "loss: 1.7616348266601562, batch: 6301 out of 17841\n",
      "loss: 1.7650511264801025, batch: 6351 out of 17841\n",
      "loss: 1.6937007904052734, batch: 6401 out of 17841\n",
      "loss: 1.8205530643463135, batch: 6451 out of 17841\n",
      "loss: 1.7061609029769897, batch: 6501 out of 17841\n",
      "loss: 1.8822455406188965, batch: 6551 out of 17841\n",
      "loss: 1.7667343616485596, batch: 6601 out of 17841\n",
      "loss: 1.8723591566085815, batch: 6651 out of 17841\n",
      "loss: 1.70583176612854, batch: 6701 out of 17841\n",
      "loss: 1.8152614831924438, batch: 6751 out of 17841\n",
      "loss: 1.8178479671478271, batch: 6801 out of 17841\n",
      "loss: 1.871020793914795, batch: 6851 out of 17841\n",
      "loss: 1.8552595376968384, batch: 6901 out of 17841\n",
      "loss: 1.7288951873779297, batch: 6951 out of 17841\n",
      "loss: 1.9943101406097412, batch: 7001 out of 17841\n",
      "loss: 1.9549736976623535, batch: 7051 out of 17841\n",
      "loss: 1.7988311052322388, batch: 7101 out of 17841\n",
      "loss: 1.8226048946380615, batch: 7151 out of 17841\n",
      "loss: 1.897787094116211, batch: 7201 out of 17841\n",
      "loss: 1.8617297410964966, batch: 7251 out of 17841\n",
      "loss: 1.7608366012573242, batch: 7301 out of 17841\n",
      "loss: 1.853460431098938, batch: 7351 out of 17841\n",
      "loss: 1.8484234809875488, batch: 7401 out of 17841\n",
      "loss: 1.823045015335083, batch: 7451 out of 17841\n",
      "loss: 1.7969037294387817, batch: 7501 out of 17841\n",
      "loss: 1.7676498889923096, batch: 7551 out of 17841\n",
      "loss: 1.9199491739273071, batch: 7601 out of 17841\n",
      "loss: 1.8036730289459229, batch: 7651 out of 17841\n",
      "loss: 1.8688786029815674, batch: 7701 out of 17841\n",
      "loss: 1.8723599910736084, batch: 7751 out of 17841\n",
      "loss: 1.7983372211456299, batch: 7801 out of 17841\n",
      "loss: 1.8908988237380981, batch: 7851 out of 17841\n",
      "loss: 1.7935097217559814, batch: 7901 out of 17841\n",
      "loss: 1.8627843856811523, batch: 7951 out of 17841\n",
      "loss: 1.7743754386901855, batch: 8001 out of 17841\n",
      "loss: 1.875337839126587, batch: 8051 out of 17841\n",
      "loss: 1.857517957687378, batch: 8101 out of 17841\n",
      "loss: 1.868234395980835, batch: 8151 out of 17841\n",
      "loss: 1.84726881980896, batch: 8201 out of 17841\n",
      "loss: 1.7577924728393555, batch: 8251 out of 17841\n",
      "loss: 1.7271838188171387, batch: 8301 out of 17841\n",
      "loss: 1.8701608180999756, batch: 8351 out of 17841\n",
      "loss: 1.8341755867004395, batch: 8401 out of 17841\n",
      "loss: 1.882108449935913, batch: 8451 out of 17841\n",
      "loss: 1.8500269651412964, batch: 8501 out of 17841\n",
      "loss: 1.7891383171081543, batch: 8551 out of 17841\n",
      "loss: 1.7454941272735596, batch: 8601 out of 17841\n",
      "loss: 1.6946721076965332, batch: 8651 out of 17841\n",
      "loss: 1.7273776531219482, batch: 8701 out of 17841\n",
      "loss: 1.838137149810791, batch: 8751 out of 17841\n",
      "loss: 1.8208789825439453, batch: 8801 out of 17841\n",
      "loss: 1.744546890258789, batch: 8851 out of 17841\n",
      "loss: 1.7612440586090088, batch: 8901 out of 17841\n",
      "loss: 1.7520073652267456, batch: 8951 out of 17841\n",
      "loss: 1.6194186210632324, batch: 9001 out of 17841\n",
      "loss: 1.7286288738250732, batch: 9051 out of 17841\n",
      "loss: 1.8892858028411865, batch: 9101 out of 17841\n",
      "loss: 1.7002633810043335, batch: 9151 out of 17841\n",
      "loss: 1.709470510482788, batch: 9201 out of 17841\n",
      "loss: 1.6638119220733643, batch: 9251 out of 17841\n",
      "loss: 1.920027732849121, batch: 9301 out of 17841\n",
      "loss: 1.711969256401062, batch: 9351 out of 17841\n",
      "loss: 1.6867529153823853, batch: 9401 out of 17841\n",
      "loss: 1.8713719844818115, batch: 9451 out of 17841\n",
      "loss: 1.7055003643035889, batch: 9501 out of 17841\n",
      "loss: 1.8418209552764893, batch: 9551 out of 17841\n",
      "loss: 1.6625454425811768, batch: 9601 out of 17841\n",
      "loss: 1.9616845846176147, batch: 9651 out of 17841\n",
      "loss: 1.8368165493011475, batch: 9701 out of 17841\n",
      "loss: 1.7194013595581055, batch: 9751 out of 17841\n",
      "loss: 1.8436765670776367, batch: 9801 out of 17841\n",
      "loss: 1.847602367401123, batch: 9851 out of 17841\n",
      "loss: 1.7829601764678955, batch: 9901 out of 17841\n",
      "loss: 1.8683626651763916, batch: 9951 out of 17841\n",
      "loss: 1.6966612339019775, batch: 10001 out of 17841\n",
      "loss: 1.8681374788284302, batch: 10051 out of 17841\n",
      "loss: 1.7615314722061157, batch: 10101 out of 17841\n",
      "loss: 1.993481993675232, batch: 10151 out of 17841\n",
      "loss: 1.8265115022659302, batch: 10201 out of 17841\n",
      "loss: 1.7262732982635498, batch: 10251 out of 17841\n",
      "loss: 1.8497860431671143, batch: 10301 out of 17841\n",
      "loss: 1.802178144454956, batch: 10351 out of 17841\n",
      "loss: 1.9437386989593506, batch: 10401 out of 17841\n",
      "loss: 1.7276099920272827, batch: 10451 out of 17841\n",
      "loss: 1.8426003456115723, batch: 10501 out of 17841\n",
      "loss: 1.8065521717071533, batch: 10551 out of 17841\n",
      "loss: 1.7153266668319702, batch: 10601 out of 17841\n",
      "loss: 1.8015708923339844, batch: 10651 out of 17841\n",
      "loss: 1.8997689485549927, batch: 10701 out of 17841\n",
      "loss: 1.8452823162078857, batch: 10751 out of 17841\n",
      "loss: 1.8034939765930176, batch: 10801 out of 17841\n",
      "loss: 1.743821382522583, batch: 10851 out of 17841\n",
      "loss: 1.774738073348999, batch: 10901 out of 17841\n",
      "loss: 1.7626960277557373, batch: 10951 out of 17841\n",
      "loss: 1.834141731262207, batch: 11001 out of 17841\n",
      "loss: 1.913525104522705, batch: 11051 out of 17841\n",
      "loss: 1.7605865001678467, batch: 11101 out of 17841\n",
      "loss: 1.709733009338379, batch: 11151 out of 17841\n",
      "loss: 1.8424906730651855, batch: 11201 out of 17841\n",
      "loss: 1.6719131469726562, batch: 11251 out of 17841\n",
      "loss: 1.7373566627502441, batch: 11301 out of 17841\n",
      "loss: 1.8041298389434814, batch: 11351 out of 17841\n",
      "loss: 1.8342534303665161, batch: 11401 out of 17841\n",
      "loss: 1.719024419784546, batch: 11451 out of 17841\n",
      "loss: 1.9549487829208374, batch: 11501 out of 17841\n",
      "loss: 1.7438857555389404, batch: 11551 out of 17841\n",
      "loss: 1.86806058883667, batch: 11601 out of 17841\n",
      "loss: 1.8208482265472412, batch: 11651 out of 17841\n",
      "loss: 1.8355646133422852, batch: 11701 out of 17841\n",
      "loss: 1.8029680252075195, batch: 11751 out of 17841\n",
      "loss: 1.781257152557373, batch: 11801 out of 17841\n",
      "loss: 1.7557964324951172, batch: 11851 out of 17841\n",
      "loss: 1.7768423557281494, batch: 11901 out of 17841\n",
      "loss: 1.7994506359100342, batch: 11951 out of 17841\n",
      "loss: 1.7833073139190674, batch: 12001 out of 17841\n",
      "loss: 1.65204918384552, batch: 12051 out of 17841\n",
      "loss: 1.7747299671173096, batch: 12101 out of 17841\n",
      "loss: 1.789055347442627, batch: 12151 out of 17841\n",
      "loss: 1.8039531707763672, batch: 12201 out of 17841\n",
      "loss: 1.856488823890686, batch: 12251 out of 17841\n",
      "loss: 1.7835659980773926, batch: 12301 out of 17841\n",
      "loss: 1.834797739982605, batch: 12351 out of 17841\n",
      "loss: 1.6969767808914185, batch: 12401 out of 17841\n",
      "loss: 1.7334587574005127, batch: 12451 out of 17841\n",
      "loss: 1.7407187223434448, batch: 12501 out of 17841\n",
      "loss: 1.821749210357666, batch: 12551 out of 17841\n",
      "loss: 1.7437324523925781, batch: 12601 out of 17841\n",
      "loss: 1.814849853515625, batch: 12651 out of 17841\n",
      "loss: 1.653592824935913, batch: 12701 out of 17841\n",
      "loss: 1.7947782278060913, batch: 12751 out of 17841\n",
      "loss: 1.6445907354354858, batch: 12801 out of 17841\n",
      "loss: 1.686319351196289, batch: 12851 out of 17841\n",
      "loss: 1.7349337339401245, batch: 12901 out of 17841\n",
      "loss: 1.8491761684417725, batch: 12951 out of 17841\n",
      "loss: 1.7204384803771973, batch: 13001 out of 17841\n",
      "loss: 1.829078197479248, batch: 13051 out of 17841\n",
      "loss: 1.8355369567871094, batch: 13101 out of 17841\n",
      "loss: 1.7696174383163452, batch: 13151 out of 17841\n",
      "loss: 1.929811954498291, batch: 13201 out of 17841\n",
      "loss: 1.6688597202301025, batch: 13251 out of 17841\n",
      "loss: 1.948811411857605, batch: 13301 out of 17841\n",
      "loss: 1.7054189443588257, batch: 13351 out of 17841\n",
      "loss: 1.9159854650497437, batch: 13401 out of 17841\n",
      "loss: 1.78618586063385, batch: 13451 out of 17841\n",
      "loss: 1.8582022190093994, batch: 13501 out of 17841\n",
      "loss: 1.7456179857254028, batch: 13551 out of 17841\n",
      "loss: 1.839293360710144, batch: 13601 out of 17841\n",
      "loss: 1.733752965927124, batch: 13651 out of 17841\n",
      "loss: 1.844800591468811, batch: 13701 out of 17841\n",
      "loss: 1.8431508541107178, batch: 13751 out of 17841\n",
      "loss: 1.8021483421325684, batch: 13801 out of 17841\n",
      "loss: 1.7671631574630737, batch: 13851 out of 17841\n",
      "loss: 1.688720941543579, batch: 13901 out of 17841\n",
      "loss: 1.882559895515442, batch: 13951 out of 17841\n",
      "loss: 1.7112407684326172, batch: 14001 out of 17841\n",
      "loss: 1.8029398918151855, batch: 14051 out of 17841\n",
      "loss: 1.7794550657272339, batch: 14101 out of 17841\n",
      "loss: 1.762895941734314, batch: 14151 out of 17841\n",
      "loss: 1.60597562789917, batch: 14201 out of 17841\n",
      "loss: 1.9001598358154297, batch: 14251 out of 17841\n",
      "loss: 1.712465763092041, batch: 14301 out of 17841\n",
      "loss: 1.7401920557022095, batch: 14351 out of 17841\n",
      "loss: 1.7444355487823486, batch: 14401 out of 17841\n",
      "loss: 1.7705597877502441, batch: 14451 out of 17841\n",
      "loss: 1.8069708347320557, batch: 14501 out of 17841\n",
      "loss: 1.5911800861358643, batch: 14551 out of 17841\n",
      "loss: 1.785049557685852, batch: 14601 out of 17841\n",
      "loss: 1.7315789461135864, batch: 14651 out of 17841\n",
      "loss: 1.7883027791976929, batch: 14701 out of 17841\n",
      "loss: 1.8422795534133911, batch: 14751 out of 17841\n",
      "loss: 1.9656004905700684, batch: 14801 out of 17841\n",
      "loss: 1.7866332530975342, batch: 14851 out of 17841\n",
      "loss: 1.891692876815796, batch: 14901 out of 17841\n",
      "loss: 1.8099608421325684, batch: 14951 out of 17841\n",
      "loss: 1.7540923357009888, batch: 15001 out of 17841\n",
      "loss: 1.893921136856079, batch: 15051 out of 17841\n",
      "loss: 1.743392825126648, batch: 15101 out of 17841\n",
      "loss: 1.9194849729537964, batch: 15151 out of 17841\n",
      "loss: 1.8101098537445068, batch: 15201 out of 17841\n",
      "loss: 1.8729841709136963, batch: 15251 out of 17841\n",
      "loss: 1.757141351699829, batch: 15301 out of 17841\n",
      "loss: 1.732612133026123, batch: 15351 out of 17841\n",
      "loss: 1.7182765007019043, batch: 15401 out of 17841\n",
      "loss: 1.7189851999282837, batch: 15451 out of 17841\n",
      "loss: 1.8175537586212158, batch: 15501 out of 17841\n",
      "loss: 1.8360552787780762, batch: 15551 out of 17841\n",
      "loss: 1.6794791221618652, batch: 15601 out of 17841\n",
      "loss: 1.8198013305664062, batch: 15651 out of 17841\n",
      "loss: 1.772064208984375, batch: 15701 out of 17841\n",
      "loss: 1.7250237464904785, batch: 15751 out of 17841\n",
      "loss: 1.8483867645263672, batch: 15801 out of 17841\n",
      "loss: 1.8361546993255615, batch: 15851 out of 17841\n",
      "loss: 1.7482190132141113, batch: 15901 out of 17841\n",
      "loss: 1.7798352241516113, batch: 15951 out of 17841\n",
      "loss: 1.8304333686828613, batch: 16001 out of 17841\n",
      "loss: 1.7971898317337036, batch: 16051 out of 17841\n",
      "loss: 1.7584857940673828, batch: 16101 out of 17841\n",
      "loss: 1.7910842895507812, batch: 16151 out of 17841\n",
      "loss: 1.685547947883606, batch: 16201 out of 17841\n",
      "loss: 1.882649540901184, batch: 16251 out of 17841\n",
      "loss: 1.896164059638977, batch: 16301 out of 17841\n",
      "loss: 1.78182053565979, batch: 16351 out of 17841\n",
      "loss: 1.869780421257019, batch: 16401 out of 17841\n",
      "loss: 1.6252442598342896, batch: 16451 out of 17841\n",
      "loss: 1.7880918979644775, batch: 16501 out of 17841\n",
      "loss: 1.770667552947998, batch: 16551 out of 17841\n",
      "loss: 1.7599377632141113, batch: 16601 out of 17841\n",
      "loss: 1.849231481552124, batch: 16651 out of 17841\n",
      "loss: 1.7778303623199463, batch: 16701 out of 17841\n",
      "loss: 1.8910161256790161, batch: 16751 out of 17841\n",
      "loss: 1.803821325302124, batch: 16801 out of 17841\n",
      "loss: 1.6652249097824097, batch: 16851 out of 17841\n",
      "loss: 1.7792248725891113, batch: 16901 out of 17841\n",
      "loss: 1.7969599962234497, batch: 16951 out of 17841\n",
      "loss: 1.821314811706543, batch: 17001 out of 17841\n",
      "loss: 1.8608269691467285, batch: 17051 out of 17841\n",
      "loss: 1.8571892976760864, batch: 17101 out of 17841\n",
      "loss: 1.8571972846984863, batch: 17151 out of 17841\n",
      "loss: 1.7836220264434814, batch: 17201 out of 17841\n",
      "loss: 1.869942307472229, batch: 17251 out of 17841\n",
      "loss: 1.7778024673461914, batch: 17301 out of 17841\n",
      "loss: 1.6997029781341553, batch: 17351 out of 17841\n",
      "loss: 1.6636972427368164, batch: 17401 out of 17841\n",
      "loss: 1.623845100402832, batch: 17451 out of 17841\n",
      "loss: 1.922166347503662, batch: 17501 out of 17841\n",
      "loss: 1.7291791439056396, batch: 17551 out of 17841\n",
      "loss: 1.89813232421875, batch: 17601 out of 17841\n",
      "loss: 1.7621949911117554, batch: 17651 out of 17841\n",
      "loss: 1.7371745109558105, batch: 17701 out of 17841\n",
      "loss: 1.8128409385681152, batch: 17751 out of 17841\n",
      "loss: 1.7435551881790161, batch: 17801 out of 17841\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 1.758539 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "perf_timer = time.perf_counter()\n",
    "perf_acc = \"\"\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_function, optimizer)\n",
    "    perf_acc = test(test_dataloader, model, loss_function)\n",
    "    \n",
    "print(perf_acc)\n",
    "perf_timer = time.perf_counter() - perf_timer\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cnn_4\"\n",
    "if True:\n",
    "    torch.save(model.state_dict(), MODELS_PATH + model_name + \".pth\")\n",
    "\n",
    "    with open(MODELS_PATH + model_name + \".txt\", \"w\") as f:\n",
    "        f.write(\"Epochs: {}\\n\".format(EPOCHS))\n",
    "        f.write(\"Feature Selection: {}\\n\".format(\"MRMR\"))\n",
    "        f.write(\"Feature Set: {}\\n\".format(FEATURES))\n",
    "        f.write(\"Model: {}\\n\".format(str(model)))\n",
    "        f.write(\"Loss Function: {}\\n\".format(\"Cross Entropy Loss\"))\n",
    "        f.write(\"Optimizer: {}\\n\\n\\n\\n\".format(str(optimizer)))\n",
    "        f.write(\"Results: {}\\n\".format(perf_acc))\n",
    "        f.write(\"Timer: {}s\\n\".format(round(perf_timer, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
